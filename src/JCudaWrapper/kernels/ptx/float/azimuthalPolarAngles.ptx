//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	toSphericalKernel

.visible .entry toSphericalKernel(
	.param .u32 toSphericalKernel_param_0,
	.param .u64 toSphericalKernel_param_1,
	.param .u32 toSphericalKernel_param_2,
	.param .u32 toSphericalKernel_param_3,
	.param .u64 toSphericalKernel_param_4,
	.param .u32 toSphericalKernel_param_5,
	.param .u32 toSphericalKernel_param_6,
	.param .u64 toSphericalKernel_param_7,
	.param .u32 toSphericalKernel_param_8,
	.param .u32 toSphericalKernel_param_9,
	.param .f32 toSphericalKernel_param_10
)
{
	.reg .pred 	%p<16>;
	.reg .f32 	%f<73>;
	.reg .b32 	%r<41>;
	.reg .b64 	%rd<16>;


	ld.param.u32 	%r8, [toSphericalKernel_param_0];
	ld.param.u64 	%rd2, [toSphericalKernel_param_1];
	ld.param.u32 	%r2, [toSphericalKernel_param_2];
	ld.param.u32 	%r3, [toSphericalKernel_param_3];
	ld.param.u64 	%rd3, [toSphericalKernel_param_4];
	ld.param.u32 	%r4, [toSphericalKernel_param_5];
	ld.param.u32 	%r5, [toSphericalKernel_param_6];
	ld.param.u64 	%rd4, [toSphericalKernel_param_7];
	ld.param.u32 	%r6, [toSphericalKernel_param_8];
	ld.param.u32 	%r7, [toSphericalKernel_param_9];
	ld.param.f32 	%f14, [toSphericalKernel_param_10];
	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r1, %r10, %r9, %r11;
	setp.ge.s32 	%p1, %r1, %r8;
	@%p1 bra 	$L__BB0_10;

	mul.lo.s32 	%r12, %r1, 3;
	div.s32 	%r13, %r12, %r3;
	mul.lo.s32 	%r14, %r13, %r2;
	cvt.s64.s32 	%rd5, %r14;
	rem.s32 	%r15, %r1, %r3;
	mul.lo.s32 	%r16, %r15, 3;
	cvt.s64.s32 	%rd6, %r16;
	add.s64 	%rd7, %rd6, %rd5;
	cvta.to.global.u64 	%rd8, %rd2;
	shl.b64 	%rd9, %rd7, 2;
	add.s64 	%rd1, %rd8, %rd9;
	ld.global.f32 	%f1, [%rd1];
	abs.f32 	%f2, %f1;
	ld.global.f32 	%f3, [%rd1+4];
	abs.f32 	%f4, %f3;
	add.f32 	%f5, %f2, %f4;
	setp.le.f32 	%p2, %f5, %f14;
	mov.f32 	%f72, 0f7FC00000;
	mov.f32 	%f71, %f72;
	@%p2 bra 	$L__BB0_7;

	setp.eq.f32 	%p3, %f2, 0f00000000;
	setp.eq.f32 	%p4, %f4, 0f00000000;
	and.pred  	%p5, %p3, %p4;
	@%p5 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_3;

$L__BB0_6:
	mov.b32 	%r27, %f1;
	shr.s32 	%r28, %r27, 31;
	and.b32  	%r29, %r28, 1078530011;
	mov.b32 	%r30, %f3;
	and.b32  	%r31, %r30, -2147483648;
	or.b32  	%r32, %r29, %r31;
	mov.b32 	%f71, %r32;
	bra.uni 	$L__BB0_7;

$L__BB0_3:
	setp.eq.f32 	%p6, %f2, 0f7F800000;
	setp.eq.f32 	%p7, %f4, 0f7F800000;
	and.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB0_5;
	bra.uni 	$L__BB0_4;

$L__BB0_5:
	mov.b32 	%r22, %f1;
	setp.lt.s32 	%p12, %r22, 0;
	selp.b32 	%r23, 1075235812, 1061752795, %p12;
	mov.b32 	%r24, %f3;
	and.b32  	%r25, %r24, -2147483648;
	or.b32  	%r26, %r23, %r25;
	mov.b32 	%f71, %r26;
	bra.uni 	$L__BB0_7;

$L__BB0_4:
	max.f32 	%f16, %f4, %f2;
	min.f32 	%f17, %f4, %f2;
	div.rn.f32 	%f18, %f17, %f16;
	mul.rn.f32 	%f19, %f18, %f18;
	mov.f32 	%f20, 0fC0B59883;
	mov.f32 	%f21, 0fBF52C7EA;
	fma.rn.f32 	%f22, %f19, %f21, %f20;
	mov.f32 	%f23, 0fC0D21907;
	fma.rn.f32 	%f24, %f22, %f19, %f23;
	mul.f32 	%f25, %f19, %f24;
	mul.f32 	%f26, %f18, %f25;
	add.f32 	%f27, %f19, 0f41355DC0;
	mov.f32 	%f28, 0f41E6BD60;
	fma.rn.f32 	%f29, %f27, %f19, %f28;
	mov.f32 	%f30, 0f419D92C8;
	fma.rn.f32 	%f31, %f29, %f19, %f30;
	rcp.rn.f32 	%f32, %f31;
	fma.rn.f32 	%f33, %f26, %f32, %f18;
	mov.f32 	%f34, 0f3FC90FDB;
	sub.f32 	%f35, %f34, %f33;
	setp.gt.f32 	%p9, %f4, %f2;
	selp.f32 	%f36, %f35, %f33, %p9;
	mov.b32 	%r17, %f1;
	setp.lt.s32 	%p10, %r17, 0;
	mov.f32 	%f37, 0f40490FDB;
	sub.f32 	%f38, %f37, %f36;
	selp.f32 	%f39, %f38, %f36, %p10;
	mov.b32 	%r18, %f39;
	mov.b32 	%r19, %f3;
	and.b32  	%r20, %r19, -2147483648;
	or.b32  	%r21, %r20, %r18;
	mov.b32 	%f40, %r21;
	setp.le.f32 	%p11, %f5, 0f7F800000;
	selp.f32 	%f71, %f40, %f5, %p11;

$L__BB0_7:
	div.s32 	%r33, %r1, %r4;
	mul.lo.s32 	%r34, %r33, %r4;
	sub.s32 	%r35, %r1, %r34;
	mad.lo.s32 	%r36, %r33, %r5, %r35;
	cvta.to.global.u64 	%rd10, %rd3;
	mul.wide.s32 	%rd11, %r36, 4;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f32 	[%rd12], %f71;
	ld.global.f32 	%f42, [%rd1];
	abs.f32 	%f43, %f42;
	ld.global.f32 	%f44, [%rd1+4];
	abs.f32 	%f45, %f44;
	add.f32 	%f46, %f43, %f45;
	ld.global.f32 	%f10, [%rd1+8];
	abs.f32 	%f11, %f10;
	add.f32 	%f47, %f46, %f11;
	setp.le.f32 	%p13, %f47, %f14;
	@%p13 bra 	$L__BB0_9;

	mov.f32 	%f48, 0f3F800000;
	sub.f32 	%f49, %f48, %f11;
	mul.f32 	%f50, %f49, 0f3F000000;
	sqrt.rn.f32 	%f51, %f50;
	setp.gt.f32 	%p14, %f11, 0f3F11EB85;
	selp.f32 	%f52, %f51, %f11, %p14;
	mul.f32 	%f53, %f52, %f52;
	mov.f32 	%f54, 0f3C94D2E9;
	mov.f32 	%f55, 0f3D53F941;
	fma.rn.f32 	%f56, %f55, %f53, %f54;
	mov.f32 	%f57, 0f3D3F841F;
	fma.rn.f32 	%f58, %f56, %f53, %f57;
	mov.f32 	%f59, 0f3D994929;
	fma.rn.f32 	%f60, %f58, %f53, %f59;
	mov.f32 	%f61, 0f3E2AAB94;
	fma.rn.f32 	%f62, %f60, %f53, %f61;
	mul.f32 	%f63, %f53, %f62;
	fma.rn.f32 	%f64, %f63, %f52, %f52;
	add.f32 	%f65, %f64, %f64;
	mov.f32 	%f66, 0f3FC90FDB;
	sub.f32 	%f67, %f66, %f64;
	selp.f32 	%f68, %f65, %f67, %p14;
	mov.f32 	%f69, 0f40490FDB;
	sub.f32 	%f70, %f69, %f68;
	setp.lt.f32 	%p15, %f10, 0f00000000;
	selp.f32 	%f72, %f70, %f68, %p15;

$L__BB0_9:
	div.s32 	%r37, %r1, %r6;
	mul.lo.s32 	%r38, %r37, %r6;
	sub.s32 	%r39, %r1, %r38;
	mad.lo.s32 	%r40, %r37, %r7, %r39;
	cvta.to.global.u64 	%rd13, %rd4;
	mul.wide.s32 	%rd14, %r40, 4;
	add.s64 	%rd15, %rd13, %rd14;
	st.global.f32 	[%rd15], %f72;

$L__BB0_10:
	ret;

}

