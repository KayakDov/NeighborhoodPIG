//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	batchGradientsKernel
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[26] = {65, 104, 111, 121, 32, 102, 114, 111, 109, 32, 98, 97, 116, 99, 104, 71, 114, 97, 100, 105, 101, 110, 116, 115, 33, 0};

.visible .entry batchGradientsKernel(
	.param .u32 batchGradientsKernel_param_0,
	.param .u64 batchGradientsKernel_param_1,
	.param .u64 batchGradientsKernel_param_2,
	.param .u32 batchGradientsKernel_param_3,
	.param .u32 batchGradientsKernel_param_4,
	.param .u64 batchGradientsKernel_param_5,
	.param .u64 batchGradientsKernel_param_6,
	.param .u32 batchGradientsKernel_param_7,
	.param .u32 batchGradientsKernel_param_8,
	.param .u64 batchGradientsKernel_param_9,
	.param .u64 batchGradientsKernel_param_10,
	.param .u32 batchGradientsKernel_param_11,
	.param .u32 batchGradientsKernel_param_12,
	.param .u64 batchGradientsKernel_param_13,
	.param .u64 batchGradientsKernel_param_14,
	.param .u32 batchGradientsKernel_param_15,
	.param .u32 batchGradientsKernel_param_16,
	.param .u64 batchGradientsKernel_param_17,
	.param .f64 batchGradientsKernel_param_18
)
{
	.reg .pred 	%p<24>;
	.reg .b32 	%r<68>;
	.reg .f64 	%fd<71>;
	.reg .b64 	%rd<104>;


	ld.param.u32 	%r24, [batchGradientsKernel_param_0];
	ld.param.u64 	%rd9, [batchGradientsKernel_param_1];
	ld.param.u64 	%rd17, [batchGradientsKernel_param_2];
	ld.param.u32 	%r16, [batchGradientsKernel_param_3];
	ld.param.u32 	%r17, [batchGradientsKernel_param_4];
	ld.param.u64 	%rd10, [batchGradientsKernel_param_5];
	ld.param.u64 	%rd11, [batchGradientsKernel_param_6];
	ld.param.u32 	%r18, [batchGradientsKernel_param_7];
	ld.param.u32 	%r19, [batchGradientsKernel_param_8];
	ld.param.u64 	%rd12, [batchGradientsKernel_param_9];
	ld.param.u64 	%rd13, [batchGradientsKernel_param_10];
	ld.param.u32 	%r20, [batchGradientsKernel_param_11];
	ld.param.u32 	%r21, [batchGradientsKernel_param_12];
	ld.param.u64 	%rd14, [batchGradientsKernel_param_13];
	ld.param.u64 	%rd15, [batchGradientsKernel_param_14];
	ld.param.u32 	%r22, [batchGradientsKernel_param_15];
	ld.param.u32 	%r23, [batchGradientsKernel_param_16];
	ld.param.u64 	%rd16, [batchGradientsKernel_param_17];
	ld.param.f64 	%fd18, [batchGradientsKernel_param_18];
	cvta.to.global.u64 	%rd1, %rd17;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r1, %r26, %r25, %r27;
	setp.ge.s32 	%p1, %r1, %r24;
	@%p1 bra 	$L__BB0_33;

	mov.u64 	%rd18, $str;
	cvta.global.u64 	%rd19, %rd18;
	mov.u64 	%rd20, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd19;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r29, [retval0+0];
	} // callseq 0
	cvta.to.global.u64 	%rd2, %rd16;
	ld.global.u32 	%r30, [%rd2+24];
	div.s32 	%r28, %r1, %r30;
	mul.lo.s32 	%r31, %r28, %r30;
	sub.s32 	%r32, %r1, %r31;
	ld.global.u32 	%r2, [%rd2+20];
	div.s32 	%r3, %r32, %r2;
	ld.global.u32 	%r4, [%rd2+16];
	div.s32 	%r33, %r32, %r4;
	ld.global.u32 	%r5, [%rd2+8];
	rem.s32 	%r6, %r33, %r5;
	mad.lo.s32 	%r34, %r3, %r17, %r6;
	mul.lo.s32 	%r35, %r33, %r4;
	sub.s32 	%r36, %r32, %r35;
	ld.global.u32 	%r7, [%rd2];
	div.s32 	%r8, %r36, %r7;
	mad.lo.s32 	%r37, %r3, %r16, %r6;
	mul.wide.s32 	%rd21, %r37, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.u32 	%r38, [%rd22];
	rem.s32 	%r9, %r32, %r7;
	mad.lo.s32 	%r10, %r38, %r8, %r9;
	cvt.s64.s32 	%rd3, %r34;
	cvta.to.global.u64 	%rd23, %rd9;
	mul.wide.s32 	%rd24, %r34, 8;
	add.s64 	%rd4, %rd23, %rd24;
	setp.eq.s32 	%p2, %r28, 0;
	@%p2 bra 	$L__BB0_24;

	setp.eq.s32 	%p3, %r28, 1;
	@%p3 bra 	$L__BB0_15;

	setp.ne.s32 	%p4, %r28, 2;
	@%p4 bra 	$L__BB0_33;

	rem.s32 	%r39, %r1, %r2;
	div.s32 	%r11, %r39, %r4;
	setp.eq.s32 	%p5, %r5, 1;
	mov.f64 	%fd67, 0d0000000000000000;
	@%p5 bra 	$L__BB0_12;

	setp.eq.s32 	%p6, %r11, 0;
	@%p6 bra 	$L__BB0_11;

	add.s32 	%r40, %r5, -1;
	setp.eq.s32 	%p7, %r40, %r11;
	@%p7 bra 	$L__BB0_10;
	bra.uni 	$L__BB0_7;

$L__BB0_10:
	ld.global.u64 	%rd39, [%rd4];
	mul.wide.s32 	%rd40, %r10, 8;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.u64 	%rd42, [%rd4+-8];
	add.s64 	%rd43, %rd42, %rd40;
	ld.f64 	%fd31, [%rd43];
	ld.f64 	%fd32, [%rd41];
	sub.f64 	%fd67, %fd32, %fd31;
	bra.uni 	$L__BB0_12;

$L__BB0_24:
	rem.s32 	%r53, %r1, %r4;
	div.s32 	%r13, %r53, %r7;
	shl.b64 	%rd77, %rd3, 2;
	add.s64 	%rd78, %rd1, %rd77;
	ld.global.u32 	%r14, [%rd78];
	ld.global.u32 	%r15, [%rd2+4];
	setp.eq.s32 	%p18, %r15, 1;
	mov.f64 	%fd70, 0d0000000000000000;
	@%p18 bra 	$L__BB0_32;

	setp.eq.s32 	%p19, %r13, 0;
	@%p19 bra 	$L__BB0_31;

	add.s32 	%r54, %r15, -1;
	setp.eq.s32 	%p20, %r54, %r13;
	@%p20 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_27;

$L__BB0_30:
	ld.global.u64 	%rd85, [%rd4];
	mul.wide.s32 	%rd86, %r10, 8;
	add.s64 	%rd87, %rd85, %rd86;
	sub.s32 	%r62, %r10, %r14;
	mul.wide.s32 	%rd88, %r62, 8;
	add.s64 	%rd89, %rd85, %rd88;
	ld.f64 	%fd63, [%rd89];
	ld.f64 	%fd64, [%rd87];
	sub.f64 	%fd70, %fd64, %fd63;
	bra.uni 	$L__BB0_32;

$L__BB0_15:
	rem.s32 	%r12, %r1, %r7;
	setp.eq.s32 	%p12, %r7, 1;
	mov.f64 	%fd69, 0d0000000000000000;
	@%p12 bra 	$L__BB0_23;

	setp.eq.s32 	%p13, %r12, 0;
	@%p13 bra 	$L__BB0_22;

	add.s32 	%r46, %r7, -1;
	setp.eq.s32 	%p14, %r46, %r12;
	@%p14 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_18;

$L__BB0_21:
	ld.global.u64 	%rd62, [%rd4];
	mul.wide.s32 	%rd63, %r10, 8;
	add.s64 	%rd64, %rd62, %rd63;
	ld.f64 	%fd47, [%rd64+-8];
	ld.f64 	%fd48, [%rd64];
	sub.f64 	%fd69, %fd48, %fd47;
	bra.uni 	$L__BB0_23;

$L__BB0_11:
	ld.global.u64 	%rd44, [%rd4+8];
	mul.wide.s32 	%rd45, %r10, 8;
	add.s64 	%rd46, %rd44, %rd45;
	ld.global.u64 	%rd47, [%rd4];
	add.s64 	%rd48, %rd47, %rd45;
	ld.f64 	%fd33, [%rd48];
	ld.f64 	%fd34, [%rd46];
	sub.f64 	%fd67, %fd34, %fd33;
	bra.uni 	$L__BB0_12;

$L__BB0_31:
	ld.global.u64 	%rd90, [%rd4];
	add.s32 	%r63, %r14, %r10;
	mul.wide.s32 	%rd91, %r63, 8;
	add.s64 	%rd92, %rd90, %rd91;
	mul.wide.s32 	%rd93, %r10, 8;
	add.s64 	%rd94, %rd90, %rd93;
	ld.f64 	%fd65, [%rd94];
	ld.f64 	%fd66, [%rd92];
	sub.f64 	%fd70, %fd66, %fd65;
	bra.uni 	$L__BB0_32;

$L__BB0_22:
	ld.global.u64 	%rd65, [%rd4];
	mul.wide.s32 	%rd66, %r10, 8;
	add.s64 	%rd67, %rd65, %rd66;
	ld.f64 	%fd49, [%rd67];
	ld.f64 	%fd50, [%rd67+8];
	sub.f64 	%fd69, %fd50, %fd49;
	bra.uni 	$L__BB0_23;

$L__BB0_27:
	setp.eq.s32 	%p21, %r13, 1;
	add.s32 	%r55, %r15, -2;
	setp.eq.s32 	%p22, %r55, %r13;
	or.pred  	%p23, %p21, %p22;
	sub.s32 	%r56, %r10, %r14;
	ld.global.u64 	%rd6, [%rd4];
	mul.wide.s32 	%rd79, %r56, 8;
	add.s64 	%rd7, %rd6, %rd79;
	add.s32 	%r57, %r14, %r10;
	mul.wide.s32 	%rd80, %r57, 8;
	add.s64 	%rd8, %rd6, %rd80;
	@%p23 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_28;

$L__BB0_29:
	ld.f64 	%fd60, [%rd8];
	ld.f64 	%fd61, [%rd7];
	sub.f64 	%fd62, %fd60, %fd61;
	mul.f64 	%fd70, %fd62, 0d3FE0000000000000;
	bra.uni 	$L__BB0_32;

$L__BB0_18:
	setp.eq.s32 	%p15, %r12, 1;
	add.s32 	%r47, %r7, -2;
	setp.eq.s32 	%p16, %r47, %r12;
	or.pred  	%p17, %p15, %p16;
	ld.global.u64 	%rd5, [%rd4];
	@%p17 bra 	$L__BB0_20;
	bra.uni 	$L__BB0_19;

$L__BB0_20:
	mul.wide.s32 	%rd60, %r10, 8;
	add.s64 	%rd61, %rd5, %rd60;
	ld.f64 	%fd44, [%rd61+-8];
	ld.f64 	%fd45, [%rd61+8];
	sub.f64 	%fd46, %fd45, %fd44;
	mul.f64 	%fd69, %fd46, 0d3FE0000000000000;
	bra.uni 	$L__BB0_23;

$L__BB0_7:
	setp.eq.s32 	%p8, %r11, 1;
	add.s32 	%r41, %r5, -2;
	setp.eq.s32 	%p9, %r41, %r11;
	or.pred  	%p10, %p8, %p9;
	@%p10 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_8;

$L__BB0_9:
	ld.global.u64 	%rd34, [%rd4+8];
	mul.wide.s32 	%rd35, %r10, 8;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.u64 	%rd37, [%rd4+-8];
	add.s64 	%rd38, %rd37, %rd35;
	ld.f64 	%fd28, [%rd38];
	ld.f64 	%fd29, [%rd36];
	sub.f64 	%fd30, %fd29, %fd28;
	mul.f64 	%fd67, %fd30, 0d3FE0000000000000;
	bra.uni 	$L__BB0_12;

$L__BB0_28:
	shl.b32 	%r58, %r14, 1;
	sub.s32 	%r59, %r10, %r58;
	mul.wide.s32 	%rd81, %r59, 8;
	add.s64 	%rd82, %rd6, %rd81;
	ld.f64 	%fd52, [%rd7];
	mul.f64 	%fd53, %fd52, 0d4020000000000000;
	ld.f64 	%fd54, [%rd82];
	sub.f64 	%fd55, %fd54, %fd53;
	ld.f64 	%fd56, [%rd8];
	fma.rn.f64 	%fd57, %fd56, 0d4020000000000000, %fd55;
	add.s32 	%r61, %r57, %r14;
	mul.wide.s32 	%rd83, %r61, 8;
	add.s64 	%rd84, %rd6, %rd83;
	ld.f64 	%fd58, [%rd84];
	sub.f64 	%fd59, %fd57, %fd58;
	div.rn.f64 	%fd70, %fd59, 0d4028000000000000;

$L__BB0_32:
	mad.lo.s32 	%r64, %r3, %r19, %r6;
	cvta.to.global.u64 	%rd95, %rd10;
	mul.wide.s32 	%rd96, %r64, 8;
	add.s64 	%rd97, %rd95, %rd96;
	mad.lo.s32 	%r65, %r3, %r18, %r6;
	cvta.to.global.u64 	%rd98, %rd11;
	mul.wide.s32 	%rd99, %r65, 4;
	add.s64 	%rd100, %rd98, %rd99;
	ld.global.u32 	%r66, [%rd100];
	mad.lo.s32 	%r67, %r66, %r8, %r9;
	ld.global.u64 	%rd101, [%rd97];
	mul.wide.s32 	%rd102, %r67, 8;
	add.s64 	%rd103, %rd101, %rd102;
	st.f64 	[%rd103], %fd70;
	bra.uni 	$L__BB0_33;

$L__BB0_19:
	add.s32 	%r48, %r10, -2;
	mul.wide.s32 	%rd58, %r48, 8;
	add.s64 	%rd59, %rd5, %rd58;
	ld.f64 	%fd36, [%rd59];
	ld.f64 	%fd37, [%rd59+8];
	mul.f64 	%fd38, %fd37, 0d4020000000000000;
	sub.f64 	%fd39, %fd36, %fd38;
	ld.f64 	%fd40, [%rd59+24];
	fma.rn.f64 	%fd41, %fd40, 0d4020000000000000, %fd39;
	ld.f64 	%fd42, [%rd59+32];
	sub.f64 	%fd43, %fd41, %fd42;
	div.rn.f64 	%fd69, %fd43, 0d4028000000000000;

$L__BB0_23:
	mad.lo.s32 	%r49, %r3, %r21, %r6;
	cvta.to.global.u64 	%rd68, %rd12;
	mul.wide.s32 	%rd69, %r49, 8;
	add.s64 	%rd70, %rd68, %rd69;
	mad.lo.s32 	%r50, %r3, %r20, %r6;
	cvta.to.global.u64 	%rd71, %rd13;
	mul.wide.s32 	%rd72, %r50, 4;
	add.s64 	%rd73, %rd71, %rd72;
	ld.global.u32 	%r51, [%rd73];
	mad.lo.s32 	%r52, %r51, %r8, %r9;
	ld.global.u64 	%rd74, [%rd70];
	mul.wide.s32 	%rd75, %r52, 8;
	add.s64 	%rd76, %rd74, %rd75;
	st.f64 	[%rd76], %fd69;
	bra.uni 	$L__BB0_33;

$L__BB0_8:
	ld.global.u64 	%rd25, [%rd4+-16];
	mul.wide.s32 	%rd26, %r10, 8;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.u64 	%rd28, [%rd4+-8];
	add.s64 	%rd29, %rd28, %rd26;
	ld.f64 	%fd20, [%rd29];
	mul.f64 	%fd21, %fd20, 0d4020000000000000;
	ld.f64 	%fd22, [%rd27];
	sub.f64 	%fd23, %fd22, %fd21;
	ld.global.u64 	%rd30, [%rd4+8];
	add.s64 	%rd31, %rd30, %rd26;
	ld.f64 	%fd24, [%rd31];
	fma.rn.f64 	%fd25, %fd24, 0d4020000000000000, %fd23;
	ld.global.u64 	%rd32, [%rd4+16];
	add.s64 	%rd33, %rd32, %rd26;
	ld.f64 	%fd26, [%rd33];
	sub.f64 	%fd27, %fd25, %fd26;
	div.rn.f64 	%fd67, %fd27, 0d4028000000000000;

$L__BB0_12:
	setp.eq.f64 	%p11, %fd18, 0d3FF0000000000000;
	@%p11 bra 	$L__BB0_14;

	div.rn.f64 	%fd67, %fd67, %fd18;

$L__BB0_14:
	mad.lo.s32 	%r42, %r3, %r23, %r6;
	cvta.to.global.u64 	%rd49, %rd14;
	mul.wide.s32 	%rd50, %r42, 8;
	add.s64 	%rd51, %rd49, %rd50;
	mad.lo.s32 	%r43, %r3, %r22, %r6;
	cvta.to.global.u64 	%rd52, %rd15;
	mul.wide.s32 	%rd53, %r43, 4;
	add.s64 	%rd54, %rd52, %rd53;
	ld.global.u32 	%r44, [%rd54];
	mad.lo.s32 	%r45, %r44, %r8, %r9;
	ld.global.u64 	%rd55, [%rd51];
	mul.wide.s32 	%rd56, %r45, 8;
	add.s64 	%rd57, %rd55, %rd56;
	st.f64 	[%rd57], %fd67;

$L__BB0_33:
	ret;

}

