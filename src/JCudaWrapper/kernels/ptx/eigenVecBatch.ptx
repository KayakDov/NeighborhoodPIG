//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	eigenVecBatchKernel
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[1];
.global .align 1 .b8 $str$1[20] = {77, 97, 116, 114, 105, 120, 32, 37, 115, 32, 40, 37, 100, 120, 37, 100, 41, 58, 10, 0};
.global .align 1 .b8 $str$2[8] = {37, 49, 48, 46, 52, 102, 32, 0};
.global .align 1 .b8 $str$3[2] = {10, 0};

.visible .entry eigenVecBatchKernel(
	.param .u32 eigenVecBatchKernel_param_0,
	.param .u64 eigenVecBatchKernel_param_1,
	.param .u32 eigenVecBatchKernel_param_2,
	.param .u64 eigenVecBatchKernel_param_3,
	.param .u32 eigenVecBatchKernel_param_4,
	.param .u64 eigenVecBatchKernel_param_5,
	.param .u64 eigenVecBatchKernel_param_6,
	.param .u64 eigenVecBatchKernel_param_7,
	.param .f64 eigenVecBatchKernel_param_8
)
{
	.local .align 16 .b8 	__local_depot0[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<78>;
	.reg .b32 	%r<267>;
	.reg .f64 	%fd<143>;
	.reg .b64 	%rd<249>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r123, [eigenVecBatchKernel_param_0];
	ld.param.u64 	%rd46, [eigenVecBatchKernel_param_1];
	ld.param.u32 	%r121, [eigenVecBatchKernel_param_2];
	ld.param.u64 	%rd50, [eigenVecBatchKernel_param_3];
	ld.param.u32 	%r122, [eigenVecBatchKernel_param_4];
	ld.param.u64 	%rd47, [eigenVecBatchKernel_param_5];
	ld.param.u64 	%rd48, [eigenVecBatchKernel_param_6];
	ld.param.u64 	%rd49, [eigenVecBatchKernel_param_7];
	ld.param.f64 	%fd18, [eigenVecBatchKernel_param_8];
	cvta.to.global.u64 	%rd1, %rd50;
	mov.u32 	%r124, %ntid.x;
	mov.u32 	%r125, %ctaid.x;
	mov.u32 	%r126, %tid.x;
	mad.lo.s32 	%r1, %r125, %r124, %r126;
	setp.ge.s32 	%p1, %r1, %r123;
	@%p1 bra 	$L__BB0_88;

	cvta.to.global.u64 	%rd51, %rd47;
	cvta.to.global.u64 	%rd2, %rd46;
	mul.lo.s32 	%r2, %r1, %r121;
	mul.lo.s32 	%r127, %r2, %r122;
	cvt.s64.s32 	%rd3, %r127;
	cvta.to.global.u64 	%rd4, %rd48;
	mul.wide.s32 	%rd52, %r127, 8;
	add.s64 	%rd5, %rd4, %rd52;
	mul.lo.s32 	%r128, %r122, %r121;
	div.s32 	%r129, %r1, %r122;
	mul.lo.s32 	%r130, %r128, %r129;
	cvt.s64.s32 	%rd6, %r130;
	mul.wide.s32 	%rd53, %r1, 8;
	add.s64 	%rd54, %rd51, %rd53;
	ld.global.f64 	%fd1, [%rd54];
	setp.lt.s32 	%p2, %r121, 1;
	setp.lt.s32 	%p3, %r122, 1;
	or.pred  	%p4, %p3, %p2;
	@%p4 bra 	$L__BB0_11;

	add.s32 	%r3, %r121, -1;
	and.b32  	%r4, %r121, 3;
	sub.s32 	%r5, %r121, %r4;
	mov.u32 	%r131, 0;
	mov.u32 	%r221, %r131;

$L__BB0_3:
	mul.lo.s32 	%r7, %r221, %r121;
	setp.lt.u32 	%p5, %r3, 3;
	mov.u32 	%r224, %r131;
	@%p5 bra 	$L__BB0_6;

	mov.u32 	%r224, 0;
	mov.u32 	%r223, %r5;

$L__BB0_5:
	add.s32 	%r134, %r224, %r7;
	cvt.s64.s32 	%rd55, %r134;
	add.s64 	%rd56, %rd55, %rd6;
	shl.b64 	%rd57, %rd56, 3;
	add.s64 	%rd58, %rd2, %rd57;
	ld.global.f64 	%fd19, [%rd58];
	mul.wide.s32 	%rd59, %r134, 8;
	add.s64 	%rd60, %rd5, %rd59;
	st.global.f64 	[%rd60], %fd19;
	ld.global.f64 	%fd20, [%rd58+8];
	st.global.f64 	[%rd60+8], %fd20;
	ld.global.f64 	%fd21, [%rd58+16];
	st.global.f64 	[%rd60+16], %fd21;
	ld.global.f64 	%fd22, [%rd58+24];
	st.global.f64 	[%rd60+24], %fd22;
	add.s32 	%r224, %r224, 4;
	add.s32 	%r223, %r223, -4;
	setp.ne.s32 	%p6, %r223, 0;
	@%p6 bra 	$L__BB0_5;

$L__BB0_6:
	setp.eq.s32 	%p7, %r4, 0;
	@%p7 bra 	$L__BB0_10;

	setp.eq.s32 	%p8, %r4, 1;
	add.s32 	%r135, %r224, %r7;
	cvt.s64.s32 	%rd61, %r135;
	add.s64 	%rd62, %rd61, %rd6;
	shl.b64 	%rd63, %rd62, 3;
	add.s64 	%rd7, %rd2, %rd63;
	ld.global.f64 	%fd23, [%rd7];
	mul.wide.s32 	%rd64, %r135, 8;
	add.s64 	%rd8, %rd5, %rd64;
	st.global.f64 	[%rd8], %fd23;
	@%p8 bra 	$L__BB0_10;

	setp.eq.s32 	%p9, %r4, 2;
	ld.global.f64 	%fd24, [%rd7+8];
	st.global.f64 	[%rd8+8], %fd24;
	@%p9 bra 	$L__BB0_10;

	ld.global.f64 	%fd25, [%rd7+16];
	st.global.f64 	[%rd8+16], %fd25;

$L__BB0_10:
	add.s32 	%r221, %r221, 1;
	setp.lt.s32 	%p10, %r221, %r122;
	@%p10 bra 	$L__BB0_3;

$L__BB0_11:
	@%p3 bra 	$L__BB0_18;

	add.s32 	%r137, %r122, -1;
	and.b32  	%r229, %r122, 3;
	setp.lt.u32 	%p12, %r137, 3;
	mov.u32 	%r227, 0;
	@%p12 bra 	$L__BB0_15;

	sub.s32 	%r226, %r122, %r229;
	mul.wide.s32 	%rd9, %r121, 8;
	add.s64 	%rd10, %rd9, 16;
	add.s64 	%rd11, %rd9, 24;

$L__BB0_14:
	mad.lo.s32 	%r139, %r227, %r121, %r227;
	mul.wide.s32 	%rd65, %r139, 8;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.f64 	%fd26, [%rd66];
	sub.f64 	%fd27, %fd26, %fd1;
	st.global.f64 	[%rd66], %fd27;
	add.s64 	%rd67, %rd66, %rd9;
	ld.global.f64 	%fd28, [%rd67+8];
	sub.f64 	%fd29, %fd28, %fd1;
	st.global.f64 	[%rd67+8], %fd29;
	add.s64 	%rd68, %rd67, %rd9;
	add.s64 	%rd69, %rd67, %rd10;
	ld.global.f64 	%fd30, [%rd69];
	sub.f64 	%fd31, %fd30, %fd1;
	st.global.f64 	[%rd69], %fd31;
	add.s64 	%rd70, %rd68, %rd11;
	ld.global.f64 	%fd32, [%rd70];
	sub.f64 	%fd33, %fd32, %fd1;
	st.global.f64 	[%rd70], %fd33;
	add.s32 	%r227, %r227, 4;
	add.s32 	%r226, %r226, -4;
	setp.ne.s32 	%p13, %r226, 0;
	@%p13 bra 	$L__BB0_14;

$L__BB0_15:
	setp.eq.s32 	%p14, %r229, 0;
	@%p14 bra 	$L__BB0_18;

$L__BB0_17:
	.pragma "nounroll";
	mad.lo.s32 	%r140, %r227, %r121, %r227;
	mul.wide.s32 	%rd71, %r140, 8;
	add.s64 	%rd72, %rd5, %rd71;
	ld.global.f64 	%fd34, [%rd72];
	sub.f64 	%fd35, %fd34, %fd1;
	st.global.f64 	[%rd72], %fd35;
	add.s32 	%r227, %r227, 1;
	add.s32 	%r229, %r229, -1;
	setp.ne.s32 	%p15, %r229, 0;
	@%p15 bra 	$L__BB0_17;

$L__BB0_18:
	setp.ne.s32 	%p16, %r1, 1;
	@%p16 bra 	$L__BB0_37;

	add.u64 	%rd73, %SP, 0;
	add.u64 	%rd12, %SPL, 0;
	mov.u64 	%rd74, $str;
	cvta.global.u64 	%rd75, %rd74;
	st.local.u64 	[%rd12], %rd75;
	st.local.v2.u32 	[%rd12+8], {%r122, %r121};
	mov.u64 	%rd76, $str$1;
	cvta.global.u64 	%rd77, %rd76;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd77;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r141, [retval0+0];
	} // callseq 0
	@%p2 bra 	$L__BB0_36;

	setp.gt.s32 	%p18, %r122, 0;
	@%p18 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_21;

$L__BB0_27:
	add.s32 	%r31, %r122, -1;
	and.b32  	%r32, %r122, 3;
	sub.s32 	%r33, %r122, %r32;
	mul.wide.s32 	%rd13, %r121, 8;
	mov.u32 	%r148, 0;
	mov.u64 	%rd86, $str$2;
	cvta.global.u64 	%rd87, %rd86;
	mov.u32 	%r232, %r148;

$L__BB0_28:
	setp.lt.u32 	%p23, %r31, 3;
	mov.u32 	%r235, %r148;
	@%p23 bra 	$L__BB0_31;

	mov.u32 	%r235, 0;
	mov.u32 	%r234, %r33;

$L__BB0_30:
	mad.lo.s32 	%r151, %r235, %r121, %r232;
	mul.wide.s32 	%rd84, %r151, 8;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.f64 	%fd36, [%rd85];
	st.local.f64 	[%rd12], %fd36;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r152, [retval0+0];
	} // callseq 6
	add.s64 	%rd89, %rd85, %rd13;
	ld.global.f64 	%fd37, [%rd89];
	st.local.f64 	[%rd12], %fd37;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r153, [retval0+0];
	} // callseq 7
	add.s64 	%rd90, %rd89, %rd13;
	ld.global.f64 	%fd38, [%rd90];
	st.local.f64 	[%rd12], %fd38;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r154, [retval0+0];
	} // callseq 8
	add.s64 	%rd91, %rd90, %rd13;
	ld.global.f64 	%fd39, [%rd91];
	st.local.f64 	[%rd12], %fd39;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r155, [retval0+0];
	} // callseq 9
	add.s32 	%r235, %r235, 4;
	add.s32 	%r234, %r234, -4;
	setp.ne.s32 	%p24, %r234, 0;
	@%p24 bra 	$L__BB0_30;

$L__BB0_31:
	setp.eq.s32 	%p25, %r32, 0;
	@%p25 bra 	$L__BB0_35;

	setp.eq.s32 	%p26, %r32, 1;
	mad.lo.s32 	%r40, %r235, %r121, %r232;
	mul.wide.s32 	%rd92, %r40, 8;
	add.s64 	%rd93, %rd5, %rd92;
	ld.global.f64 	%fd40, [%rd93];
	st.local.f64 	[%rd12], %fd40;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r156, [retval0+0];
	} // callseq 10
	@%p26 bra 	$L__BB0_35;

	setp.eq.s32 	%p27, %r32, 2;
	add.s32 	%r41, %r40, %r121;
	mul.wide.s32 	%rd97, %r41, 8;
	add.s64 	%rd98, %rd5, %rd97;
	ld.global.f64 	%fd41, [%rd98];
	st.local.f64 	[%rd12], %fd41;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r157, [retval0+0];
	} // callseq 11
	@%p27 bra 	$L__BB0_35;

	add.s32 	%r158, %r41, %r121;
	mul.wide.s32 	%rd102, %r158, 8;
	add.s64 	%rd103, %rd5, %rd102;
	ld.global.f64 	%fd42, [%rd103];
	st.local.f64 	[%rd12], %fd42;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd73;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r159, [retval0+0];
	} // callseq 12

$L__BB0_35:
	mov.u64 	%rd107, $str$3;
	cvta.global.u64 	%rd108, %rd107;
	mov.u64 	%rd109, 0;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r160, [retval0+0];
	} // callseq 13
	add.s32 	%r232, %r232, 1;
	setp.lt.s32 	%p28, %r232, %r121;
	@%p28 bra 	$L__BB0_28;
	bra.uni 	$L__BB0_36;

$L__BB0_21:
	add.s32 	%r142, %r121, -1;
	and.b32  	%r231, %r121, 3;
	setp.lt.u32 	%p19, %r142, 3;
	@%p19 bra 	$L__BB0_24;

	sub.s32 	%r230, %r121, %r231;
	mov.u64 	%rd78, $str$3;
	cvta.global.u64 	%rd79, %rd78;

$L__BB0_23:
	mov.u64 	%rd80, 0;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r143, [retval0+0];
	} // callseq 1
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r144, [retval0+0];
	} // callseq 2
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r145, [retval0+0];
	} // callseq 3
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r146, [retval0+0];
	} // callseq 4
	add.s32 	%r230, %r230, -4;
	setp.ne.s32 	%p20, %r230, 0;
	@%p20 bra 	$L__BB0_23;

$L__BB0_24:
	setp.eq.s32 	%p21, %r231, 0;
	@%p21 bra 	$L__BB0_36;

	mov.u64 	%rd81, $str$3;
	cvta.global.u64 	%rd82, %rd81;

$L__BB0_26:
	.pragma "nounroll";
	mov.u64 	%rd83, 0;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd82;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd83;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r147, [retval0+0];
	} // callseq 5
	add.s32 	%r231, %r231, -1;
	setp.eq.s32 	%p22, %r231, 0;
	@%p22 bra 	$L__BB0_36;
	bra.uni 	$L__BB0_26;

$L__BB0_36:
	mov.u64 	%rd110, $str$3;
	cvta.global.u64 	%rd111, %rd110;
	mov.u64 	%rd112, 0;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd111;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd112;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r161, [retval0+0];
	} // callseq 14

$L__BB0_37:
	cvta.to.global.u64 	%rd113, %rd49;
	mul.lo.s32 	%r163, %r1, %r122;
	mul.wide.s32 	%rd114, %r163, 4;
	add.s64 	%rd14, %rd113, %rd114;
	mov.u32 	%r238, 0;
	cvt.s64.s32 	%rd15, %r2;
	@%p3 bra 	$L__BB0_69;

	add.s32 	%r43, %r121, -2;
	add.s32 	%r44, %r122, -1;
	and.b32  	%r45, %r122, 3;
	sub.s32 	%r46, %r122, %r45;
	mul.wide.s32 	%rd16, %r121, 8;
	mov.u32 	%r236, %r238;
	mov.u32 	%r237, %r238;

$L__BB0_39:
	cvt.s64.s32 	%rd17, %r237;
	mad.lo.s32 	%r167, %r236, %r121, %r237;
	cvt.s64.s32 	%rd19, %r167;
	mul.wide.s32 	%rd115, %r167, 8;
	add.s64 	%rd20, %rd5, %rd115;
	ld.global.f64 	%fd43, [%rd20];
	abs.f64 	%fd140, %fd43;
	add.s32 	%r50, %r237, 1;
	setp.ge.s32 	%p30, %r50, %r121;
	mov.u32 	%r245, %r237;
	@%p30 bra 	$L__BB0_47;

	add.s32 	%r239, %r237, 1;
	not.b32 	%r169, %r237;
	add.s32 	%r170, %r169, %r121;
	and.b32  	%r51, %r170, 3;
	setp.eq.s32 	%p31, %r51, 0;
	mov.u32 	%r245, %r237;
	@%p31 bra 	$L__BB0_44;

	add.s32 	%r215, %r237, 1;
	ld.global.f64 	%fd45, [%rd20+8];
	abs.f64 	%fd46, %fd45;
	setp.gt.f64 	%p32, %fd46, %fd140;
	selp.b32 	%r245, %r215, %r237, %p32;
	selp.f64 	%fd140, %fd46, %fd140, %p32;
	add.s32 	%r239, %r237, 2;
	setp.eq.s32 	%p33, %r51, 1;
	@%p33 bra 	$L__BB0_44;

	ld.global.f64 	%fd47, [%rd20+16];
	abs.f64 	%fd48, %fd47;
	setp.gt.f64 	%p34, %fd48, %fd140;
	selp.b32 	%r245, %r239, %r245, %p34;
	selp.f64 	%fd140, %fd48, %fd140, %p34;
	add.s32 	%r239, %r237, 3;
	setp.eq.s32 	%p35, %r51, 2;
	@%p35 bra 	$L__BB0_44;

	ld.global.f64 	%fd49, [%rd20+24];
	abs.f64 	%fd50, %fd49;
	setp.gt.f64 	%p36, %fd50, %fd140;
	selp.b32 	%r245, %r239, %r245, %p36;
	selp.f64 	%fd140, %fd50, %fd140, %p36;
	add.s32 	%r239, %r237, 4;

$L__BB0_44:
	sub.s32 	%r171, %r43, %r237;
	setp.lt.u32 	%p37, %r171, 3;
	@%p37 bra 	$L__BB0_47;

	sub.s32 	%r61, %r239, %r237;
	mov.u32 	%r242, 0;

$L__BB0_46:
	shl.b32 	%r173, %r242, 2;
	add.s32 	%r174, %r61, %r173;
	mul.wide.s32 	%rd116, %r174, 8;
	add.s64 	%rd117, %rd20, %rd116;
	ld.global.f64 	%fd51, [%rd117];
	abs.f64 	%fd52, %fd51;
	setp.gt.f64 	%p38, %fd52, %fd140;
	selp.b32 	%r175, %r239, %r245, %p38;
	selp.f64 	%fd53, %fd52, %fd140, %p38;
	ld.global.f64 	%fd54, [%rd117+8];
	abs.f64 	%fd55, %fd54;
	setp.gt.f64 	%p39, %fd55, %fd53;
	add.s32 	%r176, %r239, 1;
	selp.b32 	%r177, %r176, %r175, %p39;
	selp.f64 	%fd56, %fd55, %fd53, %p39;
	ld.global.f64 	%fd57, [%rd117+16];
	abs.f64 	%fd58, %fd57;
	setp.gt.f64 	%p40, %fd58, %fd56;
	add.s32 	%r178, %r239, 2;
	selp.b32 	%r179, %r178, %r177, %p40;
	selp.f64 	%fd59, %fd58, %fd56, %p40;
	ld.global.f64 	%fd60, [%rd117+24];
	abs.f64 	%fd61, %fd60;
	setp.gt.f64 	%p41, %fd61, %fd59;
	add.s32 	%r180, %r239, 3;
	selp.b32 	%r245, %r180, %r179, %p41;
	selp.f64 	%fd140, %fd61, %fd59, %p41;
	add.s32 	%r239, %r239, 4;
	setp.lt.s32 	%p42, %r239, %r121;
	add.s32 	%r242, %r242, 1;
	@%p42 bra 	$L__BB0_46;

$L__BB0_47:
	mul.wide.s32 	%rd118, %r236, 4;
	add.s64 	%rd21, %rd14, %rd118;
	setp.gtu.f64 	%p43, %fd140, %fd18;
	@%p43 bra 	$L__BB0_49;
	bra.uni 	$L__BB0_48;

$L__BB0_49:
	setp.eq.s32 	%p44, %r245, %r237;
	@%p44 bra 	$L__BB0_57;

	setp.lt.u32 	%p45, %r44, 3;
	cvt.s64.s32 	%rd22, %r245;
	mov.u32 	%r248, 0;
	@%p45 bra 	$L__BB0_53;

	add.s64 	%rd23, %rd22, %rd3;
	mov.u32 	%r247, %r46;

$L__BB0_52:
	cvt.s64.s32 	%rd237, %r237;
	add.s64 	%rd236, %rd237, %rd3;
	mul.lo.s32 	%r184, %r248, %r121;
	cvt.s64.s32 	%rd119, %r184;
	add.s64 	%rd120, %rd23, %rd119;
	shl.b64 	%rd121, %rd120, 3;
	add.s64 	%rd122, %rd4, %rd121;
	add.s64 	%rd123, %rd236, %rd119;
	shl.b64 	%rd124, %rd123, 3;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.f64 	%fd62, [%rd122];
	ld.global.f64 	%fd63, [%rd125];
	st.global.f64 	[%rd122], %fd63;
	st.global.f64 	[%rd125], %fd62;
	add.s64 	%rd126, %rd122, %rd16;
	ld.global.f64 	%fd64, [%rd126];
	add.s64 	%rd127, %rd125, %rd16;
	ld.global.f64 	%fd65, [%rd127];
	st.global.f64 	[%rd126], %fd65;
	st.global.f64 	[%rd127], %fd64;
	add.s64 	%rd128, %rd126, %rd16;
	ld.global.f64 	%fd66, [%rd128];
	add.s64 	%rd129, %rd127, %rd16;
	ld.global.f64 	%fd67, [%rd129];
	st.global.f64 	[%rd128], %fd67;
	st.global.f64 	[%rd129], %fd66;
	add.s64 	%rd130, %rd128, %rd16;
	ld.global.f64 	%fd68, [%rd130];
	add.s64 	%rd131, %rd129, %rd16;
	ld.global.f64 	%fd69, [%rd131];
	st.global.f64 	[%rd130], %fd69;
	st.global.f64 	[%rd131], %fd68;
	add.s32 	%r248, %r248, 4;
	add.s32 	%r247, %r247, -4;
	setp.ne.s32 	%p46, %r247, 0;
	@%p46 bra 	$L__BB0_52;

$L__BB0_53:
	setp.eq.s32 	%p47, %r45, 0;
	@%p47 bra 	$L__BB0_57;

	setp.eq.s32 	%p48, %r45, 1;
	mul.lo.s32 	%r75, %r248, %r121;
	cvt.s64.s32 	%rd132, %r75;
	add.s64 	%rd133, %rd22, %rd132;
	sub.s64 	%rd134, %rd133, %rd19;
	shl.b64 	%rd135, %rd134, 3;
	add.s64 	%rd136, %rd20, %rd135;
	ld.global.f64 	%fd70, [%rd136];
	add.s64 	%rd137, %rd17, %rd132;
	sub.s64 	%rd138, %rd137, %rd19;
	shl.b64 	%rd139, %rd138, 3;
	add.s64 	%rd140, %rd20, %rd139;
	ld.global.f64 	%fd71, [%rd140];
	st.global.f64 	[%rd136], %fd71;
	st.global.f64 	[%rd140], %fd70;
	@%p48 bra 	$L__BB0_57;

	setp.eq.s32 	%p49, %r45, 2;
	add.s32 	%r76, %r75, %r121;
	cvt.s64.s32 	%rd141, %r76;
	add.s64 	%rd142, %rd22, %rd141;
	sub.s64 	%rd143, %rd142, %rd19;
	shl.b64 	%rd144, %rd143, 3;
	add.s64 	%rd145, %rd20, %rd144;
	ld.global.f64 	%fd72, [%rd145];
	add.s64 	%rd146, %rd17, %rd141;
	sub.s64 	%rd147, %rd146, %rd19;
	shl.b64 	%rd148, %rd147, 3;
	add.s64 	%rd149, %rd20, %rd148;
	ld.global.f64 	%fd73, [%rd149];
	st.global.f64 	[%rd145], %fd73;
	st.global.f64 	[%rd149], %fd72;
	@%p49 bra 	$L__BB0_57;

	add.s32 	%r185, %r76, %r121;
	cvt.s64.s32 	%rd150, %r185;
	add.s64 	%rd151, %rd22, %rd150;
	sub.s64 	%rd152, %rd151, %rd19;
	shl.b64 	%rd153, %rd152, 3;
	add.s64 	%rd154, %rd20, %rd153;
	ld.global.f64 	%fd74, [%rd154];
	add.s64 	%rd155, %rd17, %rd150;
	sub.s64 	%rd156, %rd155, %rd19;
	shl.b64 	%rd157, %rd156, 3;
	add.s64 	%rd158, %rd20, %rd157;
	ld.global.f64 	%fd75, [%rd158];
	st.global.f64 	[%rd154], %fd75;
	st.global.f64 	[%rd158], %fd74;

$L__BB0_57:
	add.s32 	%r216, %r237, 1;
	setp.ge.s32 	%p77, %r216, %r121;
	@%p77 bra 	$L__BB0_67;

	add.s32 	%r250, %r237, 1;
	shl.b64 	%rd160, %rd19, 3;
	sub.s64 	%rd24, %rd20, %rd160;
	add.s64 	%rd25, %rd24, 8;
	mov.u64 	%rd244, 0;
	mov.u32 	%r249, 0;

$L__BB0_59:
	mov.u32 	%r253, 0;
	mad.lo.s32 	%r219, %r121, %r236, %r237;
	shl.b64 	%rd161, %rd244, 3;
	add.s64 	%rd162, %rd20, %rd161;
	add.s64 	%rd27, %rd162, 8;
	neg.s32 	%r188, %r249;
	add.s32 	%r189, %r237, %r249;
	cvt.s64.s32 	%rd28, %r189;
	add.s32 	%r190, %r219, %r249;
	cvt.s64.s32 	%rd29, %r190;
	mul.wide.s32 	%rd163, %r188, 8;
	add.s64 	%rd164, %rd27, %rd163;
	ld.global.f64 	%fd76, [%rd164+-8];
	ld.global.f64 	%fd77, [%rd162+8];
	div.rn.f64 	%fd11, %fd77, %fd76;
	setp.lt.u32 	%p51, %r44, 3;
	@%p51 bra 	$L__BB0_62;

	mov.u32 	%r253, 0;
	mov.u32 	%r252, %r46;

$L__BB0_61:
	cvt.s64.s32 	%rd241, %r250;
	add.s64 	%rd240, %rd241, %rd3;
	cvt.s64.s32 	%rd239, %r237;
	add.s64 	%rd238, %rd239, %rd3;
	mul.lo.s32 	%r192, %r253, %r121;
	cvt.s64.s32 	%rd166, %r192;
	add.s64 	%rd167, %rd238, %rd166;
	shl.b64 	%rd168, %rd167, 3;
	add.s64 	%rd169, %rd4, %rd168;
	ld.global.f64 	%fd78, [%rd169];
	mul.f64 	%fd79, %fd11, %fd78;
	add.s64 	%rd170, %rd240, %rd166;
	shl.b64 	%rd171, %rd170, 3;
	add.s64 	%rd172, %rd4, %rd171;
	ld.global.f64 	%fd80, [%rd172];
	sub.f64 	%fd81, %fd80, %fd79;
	st.global.f64 	[%rd172], %fd81;
	add.s64 	%rd173, %rd169, %rd16;
	ld.global.f64 	%fd82, [%rd173];
	mul.f64 	%fd83, %fd11, %fd82;
	add.s64 	%rd174, %rd172, %rd16;
	ld.global.f64 	%fd84, [%rd174];
	sub.f64 	%fd85, %fd84, %fd83;
	st.global.f64 	[%rd174], %fd85;
	add.s64 	%rd175, %rd173, %rd16;
	ld.global.f64 	%fd86, [%rd175];
	mul.f64 	%fd87, %fd11, %fd86;
	add.s64 	%rd176, %rd174, %rd16;
	ld.global.f64 	%fd88, [%rd176];
	sub.f64 	%fd89, %fd88, %fd87;
	st.global.f64 	[%rd176], %fd89;
	add.s64 	%rd177, %rd175, %rd16;
	ld.global.f64 	%fd90, [%rd177];
	mul.f64 	%fd91, %fd11, %fd90;
	add.s64 	%rd178, %rd176, %rd16;
	ld.global.f64 	%fd92, [%rd178];
	sub.f64 	%fd93, %fd92, %fd91;
	st.global.f64 	[%rd178], %fd93;
	add.s32 	%r253, %r253, 4;
	add.s32 	%r252, %r252, -4;
	setp.ne.s32 	%p52, %r252, 0;
	@%p52 bra 	$L__BB0_61;

$L__BB0_62:
	setp.eq.s32 	%p53, %r45, 0;
	@%p53 bra 	$L__BB0_66;

	setp.eq.s32 	%p54, %r45, 1;
	mul.lo.s32 	%r85, %r253, %r121;
	cvt.s64.s32 	%rd179, %r85;
	add.s64 	%rd180, %rd17, %rd179;
	shl.b64 	%rd181, %rd180, 3;
	add.s64 	%rd182, %rd24, %rd181;
	ld.global.f64 	%fd94, [%rd182];
	mul.f64 	%fd95, %fd11, %fd94;
	add.s64 	%rd183, %rd28, %rd179;
	shl.b64 	%rd184, %rd183, 3;
	add.s64 	%rd185, %rd25, %rd184;
	ld.global.f64 	%fd96, [%rd185];
	sub.f64 	%fd97, %fd96, %fd95;
	st.global.f64 	[%rd185], %fd97;
	@%p54 bra 	$L__BB0_66;

	setp.eq.s32 	%p55, %r45, 2;
	add.s32 	%r86, %r85, %r121;
	cvt.s64.s32 	%rd186, %r86;
	add.s64 	%rd187, %rd17, %rd186;
	shl.b64 	%rd188, %rd187, 3;
	add.s64 	%rd189, %rd24, %rd188;
	ld.global.f64 	%fd98, [%rd189];
	mul.f64 	%fd99, %fd11, %fd98;
	add.s64 	%rd190, %rd28, %rd186;
	sub.s64 	%rd191, %rd190, %rd29;
	shl.b64 	%rd192, %rd191, 3;
	add.s64 	%rd193, %rd27, %rd192;
	ld.global.f64 	%fd100, [%rd193];
	sub.f64 	%fd101, %fd100, %fd99;
	st.global.f64 	[%rd193], %fd101;
	@%p55 bra 	$L__BB0_66;

	add.s32 	%r193, %r86, %r121;
	cvt.s64.s32 	%rd194, %r193;
	add.s64 	%rd195, %rd17, %rd194;
	shl.b64 	%rd196, %rd195, 3;
	add.s64 	%rd197, %rd24, %rd196;
	ld.global.f64 	%fd102, [%rd197];
	mul.f64 	%fd103, %fd11, %fd102;
	add.s64 	%rd198, %rd28, %rd194;
	sub.s64 	%rd199, %rd198, %rd29;
	shl.b64 	%rd200, %rd199, 3;
	add.s64 	%rd201, %rd27, %rd200;
	ld.global.f64 	%fd104, [%rd201];
	sub.f64 	%fd105, %fd104, %fd103;
	st.global.f64 	[%rd201], %fd105;

$L__BB0_66:
	add.s32 	%r250, %r250, 1;
	setp.lt.s32 	%p56, %r250, %r121;
	add.s64 	%rd244, %rd244, 1;
	add.s32 	%r249, %r249, 1;
	@%p56 bra 	$L__BB0_59;

$L__BB0_67:
	mul.wide.s32 	%rd243, %r236, 4;
	add.s64 	%rd242, %rd14, %rd243;
	add.s32 	%r237, %r237, 1;
	mov.u32 	%r194, 1;
	st.global.u32 	[%rd242], %r194;
	bra.uni 	$L__BB0_68;

$L__BB0_48:
	mov.u32 	%r181, 0;
	st.global.u32 	[%rd21], %r181;
	add.s32 	%r238, %r238, 1;

$L__BB0_68:
	add.s32 	%r236, %r236, 1;
	setp.lt.s32 	%p57, %r236, %r122;
	@%p57 bra 	$L__BB0_39;

$L__BB0_69:
	ld.global.f64 	%fd106, [%rd5];
	abs.f64 	%fd107, %fd106;
	setp.geu.f64 	%p58, %fd107, %fd18;
	@%p58 bra 	$L__BB0_71;

	mov.u32 	%r195, 0;
	st.global.u32 	[%rd14], %r195;

$L__BB0_71:
	setp.lt.s32 	%p76, %r122, 1;
	mov.u32 	%r213, %tid.x;
	mov.u32 	%r212, %ntid.x;
	mov.u32 	%r211, %ctaid.x;
	mad.lo.s32 	%r210, %r211, %r212, %r213;
	rem.s32 	%r93, %r210, %r238;
	setp.lt.s32 	%p60, %r93, 0;
	mov.u32 	%r260, -1;
	add.s32 	%r266, %r122, -1;
	cvt.s64.s32 	%rd245, %r266;
	or.pred  	%p61, %p76, %p60;
	@%p61 bra 	$L__BB0_75;

	mov.u32 	%r259, 0;
	mov.u32 	%r258, %r93;

$L__BB0_73:
	shl.b64 	%rd202, %rd245, 2;
	add.s64 	%rd203, %rd14, %rd202;
	ld.global.u32 	%r198, [%rd203];
	setp.eq.s32 	%p62, %r198, 0;
	setp.ne.s32 	%p63, %r198, 0;
	selp.u32 	%r199, 1, 0, %p63;
	add.s32 	%r259, %r259, %r199;
	selp.b32 	%r200, -1, 0, %p62;
	add.s32 	%r258, %r258, %r200;
	add.s64 	%rd204, %rd245, %rd15;
	shl.b64 	%rd205, %rd204, 3;
	add.s64 	%rd206, %rd1, %rd205;
	mov.u64 	%rd207, 0;
	st.global.u64 	[%rd206], %rd207;
	setp.gt.s32 	%p64, %r258, -1;
	setp.gt.s32 	%p65, %r266, 0;
	and.pred  	%p66, %p65, %p64;
	add.s32 	%r266, %r266, -1;
	cvt.s64.s32 	%rd245, %r266;
	@%p66 bra 	$L__BB0_73;

	not.b32 	%r260, %r259;

$L__BB0_75:
	add.s64 	%rd208, %rd245, %rd15;
	shl.b64 	%rd209, %rd208, 3;
	add.s64 	%rd210, %rd1, %rd209;
	mov.u64 	%rd211, 4607182418800017408;
	st.global.u64 	[%rd210], %rd211;
	sub.s32 	%r201, %r122, %r238;
	add.s32 	%r262, %r201, %r260;
	setp.lt.s32 	%p67, %r262, 0;
	@%p67 bra 	$L__BB0_88;

	sub.s32 	%r105, %r122, %r93;
	not.b32 	%r202, %r93;
	add.s32 	%r106, %r202, %r122;
	shl.b64 	%rd212, %rd15, 3;
	add.s64 	%rd213, %rd1, %rd212;
	add.s64 	%rd36, %rd213, 16;
	mul.wide.s32 	%rd37, %r121, 8;

$L__BB0_77:
	cvt.s64.s32 	%rd214, %r262;
	add.s64 	%rd215, %rd214, %rd15;
	shl.b64 	%rd216, %rd215, 3;
	add.s64 	%rd38, %rd1, %rd216;
	mov.u64 	%rd217, 0;
	st.global.u64 	[%rd38], %rd217;
	cvt.s64.s32 	%rd218, %r266;
	add.s64 	%rd219, %rd218, %rd15;
	shl.b64 	%rd220, %rd219, 3;
	add.s64 	%rd39, %rd1, %rd220;
	setp.le.s32 	%p68, %r105, %r266;
	@%p68 bra 	$L__BB0_85;

	sub.s32 	%r203, %r105, %r266;
	and.b32  	%r109, %r203, 3;
	setp.eq.s32 	%p69, %r109, 0;
	mov.f64 	%fd141, 0d0000000000000000;
	mov.u32 	%r264, %r266;
	@%p69 bra 	$L__BB0_82;

	add.s32 	%r264, %r266, 1;
	mad.lo.s32 	%r111, %r264, %r121, %r262;
	mul.wide.s32 	%rd221, %r111, 8;
	add.s64 	%rd222, %rd5, %rd221;
	ld.global.f64 	%fd109, [%rd222];
	ld.global.f64 	%fd110, [%rd39+8];
	mul.f64 	%fd111, %fd110, %fd109;
	mov.f64 	%fd112, 0d0000000000000000;
	sub.f64 	%fd141, %fd112, %fd111;
	st.global.f64 	[%rd38], %fd141;
	setp.eq.s32 	%p70, %r109, 1;
	@%p70 bra 	$L__BB0_82;

	add.s32 	%r264, %r266, 2;
	add.s32 	%r113, %r111, %r121;
	mul.wide.s32 	%rd223, %r113, 8;
	add.s64 	%rd224, %rd5, %rd223;
	ld.global.f64 	%fd113, [%rd224];
	ld.global.f64 	%fd114, [%rd39+16];
	mul.f64 	%fd115, %fd114, %fd113;
	sub.f64 	%fd141, %fd141, %fd115;
	st.global.f64 	[%rd38], %fd141;
	setp.eq.s32 	%p71, %r109, 2;
	@%p71 bra 	$L__BB0_82;

	add.s32 	%r264, %r266, 3;
	add.s32 	%r204, %r113, %r121;
	mul.wide.s32 	%rd225, %r204, 8;
	add.s64 	%rd226, %rd5, %rd225;
	ld.global.f64 	%fd116, [%rd226];
	ld.global.f64 	%fd117, [%rd39+24];
	mul.f64 	%fd118, %fd117, %fd116;
	sub.f64 	%fd141, %fd141, %fd118;
	st.global.f64 	[%rd38], %fd141;

$L__BB0_82:
	sub.s32 	%r205, %r106, %r266;
	setp.lt.u32 	%p72, %r205, 3;
	@%p72 bra 	$L__BB0_85;

	add.s32 	%r206, %r264, 1;
	mad.lo.s32 	%r207, %r121, %r206, %r262;
	mul.wide.s32 	%rd227, %r207, 8;
	add.s64 	%rd248, %rd5, %rd227;
	mul.wide.s32 	%rd228, %r264, 8;
	add.s64 	%rd247, %rd36, %rd228;

$L__BB0_84:
	ld.global.f64 	%fd119, [%rd248];
	ld.global.f64 	%fd120, [%rd247+-8];
	mul.f64 	%fd121, %fd120, %fd119;
	sub.f64 	%fd122, %fd141, %fd121;
	st.global.f64 	[%rd38], %fd122;
	add.s64 	%rd229, %rd248, %rd37;
	ld.global.f64 	%fd123, [%rd229];
	ld.global.f64 	%fd124, [%rd247];
	mul.f64 	%fd125, %fd124, %fd123;
	sub.f64 	%fd126, %fd122, %fd125;
	st.global.f64 	[%rd38], %fd126;
	add.s64 	%rd230, %rd229, %rd37;
	ld.global.f64 	%fd127, [%rd230];
	ld.global.f64 	%fd128, [%rd247+8];
	mul.f64 	%fd129, %fd128, %fd127;
	sub.f64 	%fd130, %fd126, %fd129;
	st.global.f64 	[%rd38], %fd130;
	add.s64 	%rd231, %rd230, %rd37;
	add.s64 	%rd248, %rd231, %rd37;
	ld.global.f64 	%fd131, [%rd231];
	ld.global.f64 	%fd132, [%rd247+16];
	mul.f64 	%fd133, %fd132, %fd131;
	sub.f64 	%fd141, %fd130, %fd133;
	st.global.f64 	[%rd38], %fd141;
	add.s64 	%rd247, %rd247, 32;
	add.s32 	%r264, %r264, 4;
	setp.lt.s32 	%p73, %r264, %r105;
	@%p73 bra 	$L__BB0_84;

$L__BB0_85:
	mad.lo.s32 	%r208, %r266, %r121, %r262;
	mul.wide.s32 	%rd232, %r208, 8;
	add.s64 	%rd233, %rd5, %rd232;
	ld.global.f64 	%fd134, [%rd39];
	ld.global.f64 	%fd135, [%rd233];
	div.rn.f64 	%fd136, %fd134, %fd135;
	st.global.f64 	[%rd39], %fd136;

$L__BB0_86:
	mov.u32 	%r118, %r266;
	mul.wide.s32 	%rd234, %r118, 4;
	add.s64 	%rd235, %rd14, %rd234;
	ld.global.u32 	%r209, [%rd235];
	setp.eq.s32 	%p74, %r209, 0;
	add.s32 	%r266, %r118, -1;
	@%p74 bra 	$L__BB0_86;

	add.s32 	%r120, %r262, -1;
	setp.gt.s32 	%p75, %r262, 0;
	mov.u32 	%r262, %r120;
	mov.u32 	%r266, %r118;
	@%p75 bra 	$L__BB0_77;

$L__BB0_88:
	ret;

}

