//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	neighborhoodSum3dKernel

.visible .entry neighborhoodSum3dKernel(
	.param .u32 neighborhoodSum3dKernel_param_0,
	.param .u64 neighborhoodSum3dKernel_param_1,
	.param .u64 neighborhoodSum3dKernel_param_2,
	.param .u32 neighborhoodSum3dKernel_param_3,
	.param .u32 neighborhoodSum3dKernel_param_4,
	.param .u32 neighborhoodSum3dKernel_param_5,
	.param .u32 neighborhoodSum3dKernel_param_6,
	.param .u32 neighborhoodSum3dKernel_param_7,
	.param .u32 neighborhoodSum3dKernel_param_8,
	.param .u32 neighborhoodSum3dKernel_param_9,
	.param .u32 neighborhoodSum3dKernel_param_10
)
{
	.reg .pred 	%p<24>;
	.reg .b32 	%r<111>;
	.reg .f64 	%fd<93>;
	.reg .b64 	%rd<196>;


	ld.param.u32 	%r53, [neighborhoodSum3dKernel_param_0];
	ld.param.u64 	%rd108, [neighborhoodSum3dKernel_param_1];
	ld.param.u64 	%rd109, [neighborhoodSum3dKernel_param_2];
	ld.param.u32 	%r46, [neighborhoodSum3dKernel_param_3];
	ld.param.u32 	%r47, [neighborhoodSum3dKernel_param_4];
	ld.param.u32 	%r48, [neighborhoodSum3dKernel_param_6];
	ld.param.u32 	%r49, [neighborhoodSum3dKernel_param_7];
	ld.param.u32 	%r50, [neighborhoodSum3dKernel_param_8];
	ld.param.u32 	%r51, [neighborhoodSum3dKernel_param_9];
	ld.param.u32 	%r52, [neighborhoodSum3dKernel_param_10];
	cvta.to.global.u64 	%rd1, %rd109;
	cvta.to.global.u64 	%rd2, %rd108;
	mov.u32 	%r54, %ntid.x;
	mov.u32 	%r55, %ctaid.x;
	mov.u32 	%r56, %tid.x;
	mad.lo.s32 	%r89, %r55, %r54, %r56;
	setp.ge.s32 	%p1, %r89, %r53;
	@%p1 bra 	$L__BB0_33;

	setp.eq.s32 	%p2, %r52, 0;
	@%p2 bra 	$L__BB0_4;

	setp.ne.s32 	%p3, %r52, 1;
	@%p3 bra 	$L__BB0_5;

	mul.lo.s32 	%r89, %r89, %r46;
	bra.uni 	$L__BB0_5;

$L__BB0_4:
	div.s32 	%r57, %r89, %r46;
	mul.lo.s32 	%r58, %r57, %r46;
	sub.s32 	%r59, %r89, %r58;
	mul.lo.s32 	%r60, %r47, %r46;
	mad.lo.s32 	%r89, %r60, %r57, %r59;

$L__BB0_5:
	cvt.s64.s32 	%rd3, %r89;
	mul.wide.s32 	%rd110, %r89, 8;
	add.s64 	%rd186, %rd2, %rd110;
	mul.lo.s32 	%r61, %r89, %r50;
	cvt.s64.s32 	%rd5, %r61;
	setp.lt.s32 	%p4, %r51, 0;
	mov.f64 	%fd84, 0d0000000000000000;
	@%p4 bra 	$L__BB0_12;

	add.s32 	%r63, %r51, 1;
	and.b32  	%r93, %r63, 3;
	setp.lt.u32 	%p5, %r51, 3;
	mov.f64 	%fd84, 0d0000000000000000;
	mov.u32 	%r92, 0;
	@%p5 bra 	$L__BB0_9;

	sub.s32 	%r90, %r51, %r93;
	mul.wide.s32 	%rd6, %r48, 8;
	mov.u64 	%rd160, %rd186;

$L__BB0_8:
	ld.global.f64 	%fd31, [%rd160];
	add.f64 	%fd32, %fd84, %fd31;
	add.s64 	%rd111, %rd160, %rd6;
	ld.global.f64 	%fd33, [%rd111];
	add.f64 	%fd34, %fd32, %fd33;
	add.s64 	%rd112, %rd111, %rd6;
	ld.global.f64 	%fd35, [%rd112];
	add.f64 	%fd36, %fd34, %fd35;
	add.s64 	%rd113, %rd112, %rd6;
	add.s64 	%rd160, %rd113, %rd6;
	ld.global.f64 	%fd37, [%rd113];
	add.f64 	%fd84, %fd36, %fd37;
	add.s32 	%r92, %r92, 4;
	add.s32 	%r90, %r90, -4;
	setp.ne.s32 	%p6, %r90, -1;
	@%p6 bra 	$L__BB0_8;

$L__BB0_9:
	setp.eq.s32 	%p7, %r93, 0;
	@%p7 bra 	$L__BB0_12;

	mul.lo.s32 	%r65, %r92, %r48;
	cvt.s64.s32 	%rd114, %r65;
	add.s64 	%rd115, %rd3, %rd114;
	shl.b64 	%rd116, %rd115, 3;
	add.s64 	%rd161, %rd2, %rd116;
	mul.wide.s32 	%rd10, %r48, 8;

$L__BB0_11:
	.pragma "nounroll";
	ld.global.f64 	%fd38, [%rd161];
	add.f64 	%fd84, %fd84, %fd38;
	add.s64 	%rd161, %rd161, %rd10;
	add.s32 	%r93, %r93, -1;
	setp.ne.s32 	%p8, %r93, 0;
	@%p8 bra 	$L__BB0_11;

$L__BB0_12:
	shl.b64 	%rd117, %rd5, 3;
	add.s64 	%rd185, %rd1, %rd117;
	st.global.f64 	[%rd185], %fd84;
	setp.lt.s32 	%p9, %r51, 1;
	mov.u32 	%r106, 1;
	@%p9 bra 	$L__BB0_19;

	cvt.s64.s32 	%rd14, %r48;
	mul.lo.s32 	%r69, %r50, %r48;
	cvt.s64.s32 	%rd15, %r69;
	mul.lo.s32 	%r70, %r51, %r48;
	cvt.s64.s32 	%rd16, %r70;
	and.b32  	%r99, %r51, 3;
	add.s32 	%r71, %r51, -1;
	setp.lt.u32 	%p10, %r71, 3;
	mov.u32 	%r106, 1;
	@%p10 bra 	$L__BB0_16;

	sub.s32 	%r95, %r51, %r99;
	shl.b64 	%rd17, %rd14, 5;
	shl.b64 	%rd18, %rd14, 3;
	shl.b64 	%rd19, %rd15, 5;
	shl.b64 	%rd20, %rd15, 3;
	add.s64 	%rd119, %rd15, %rd5;
	shl.b64 	%rd120, %rd119, 3;
	add.s64 	%rd164, %rd1, %rd120;
	add.s64 	%rd121, %rd3, %rd14;
	add.s64 	%rd122, %rd121, %rd16;
	shl.b64 	%rd123, %rd122, 3;
	add.s64 	%rd165, %rd2, %rd123;

$L__BB0_15:
	ld.global.f64 	%fd40, [%rd165];
	add.f64 	%fd41, %fd84, %fd40;
	st.global.f64 	[%rd164], %fd41;
	add.s64 	%rd124, %rd165, %rd18;
	ld.global.f64 	%fd42, [%rd124];
	add.f64 	%fd43, %fd41, %fd42;
	add.s64 	%rd125, %rd164, %rd20;
	st.global.f64 	[%rd125], %fd43;
	add.s64 	%rd126, %rd124, %rd18;
	ld.global.f64 	%fd44, [%rd126];
	add.f64 	%fd45, %fd43, %fd44;
	add.s64 	%rd127, %rd125, %rd20;
	st.global.f64 	[%rd127], %fd45;
	add.s64 	%rd128, %rd126, %rd18;
	add.s64 	%rd165, %rd128, %rd18;
	ld.global.f64 	%fd46, [%rd128];
	add.f64 	%fd84, %fd45, %fd46;
	add.s64 	%rd129, %rd127, %rd20;
	add.s64 	%rd164, %rd129, %rd20;
	st.global.f64 	[%rd129], %fd84;
	add.s32 	%r106, %r106, 4;
	add.s64 	%rd186, %rd186, %rd17;
	add.s64 	%rd185, %rd185, %rd19;
	add.s32 	%r95, %r95, -4;
	setp.ne.s32 	%p11, %r95, 0;
	@%p11 bra 	$L__BB0_15;

$L__BB0_16:
	setp.eq.s32 	%p12, %r99, 0;
	@%p12 bra 	$L__BB0_19;

	shl.b64 	%rd35, %rd14, 3;
	shl.b64 	%rd130, %rd16, 3;
	add.s64 	%rd36, %rd35, %rd130;
	shl.b64 	%rd37, %rd15, 3;

$L__BB0_18:
	.pragma "nounroll";
	add.s64 	%rd185, %rd185, %rd37;
	add.s64 	%rd131, %rd186, %rd36;
	ld.global.f64 	%fd47, [%rd131];
	add.f64 	%fd84, %fd84, %fd47;
	st.global.f64 	[%rd185], %fd84;
	add.s32 	%r106, %r106, 1;
	add.s64 	%rd186, %rd186, %rd35;
	add.s32 	%r99, %r99, -1;
	setp.ne.s32 	%p13, %r99, 0;
	@%p13 bra 	$L__BB0_18;

$L__BB0_19:
	sub.s32 	%r27, %r49, %r51;
	setp.ge.s32 	%p14, %r106, %r27;
	@%p14 bra 	$L__BB0_26;

	cvt.s64.s32 	%rd44, %r48;
	mul.lo.s32 	%r74, %r50, %r48;
	cvt.s64.s32 	%rd45, %r74;
	mul.lo.s32 	%r75, %r51, %r48;
	cvt.s64.s32 	%rd46, %r75;
	not.b32 	%r76, %r51;
	mul.lo.s32 	%r77, %r76, %r48;
	cvt.s64.s32 	%rd47, %r77;
	sub.s32 	%r78, %r49, %r106;
	sub.s32 	%r79, %r78, %r51;
	and.b32  	%r102, %r79, 3;
	setp.eq.s32 	%p15, %r102, 0;
	mov.u32 	%r103, %r106;
	@%p15 bra 	$L__BB0_23;

	shl.b64 	%rd48, %rd44, 3;
	shl.b64 	%rd133, %rd47, 3;
	add.s64 	%rd49, %rd48, %rd133;
	shl.b64 	%rd134, %rd46, 3;
	add.s64 	%rd50, %rd48, %rd134;
	shl.b64 	%rd51, %rd45, 3;
	mov.u32 	%r103, %r106;

$L__BB0_22:
	.pragma "nounroll";
	add.s64 	%rd185, %rd185, %rd51;
	add.s64 	%rd135, %rd186, %rd50;
	add.s64 	%rd136, %rd186, %rd49;
	ld.global.f64 	%fd49, [%rd136];
	ld.global.f64 	%fd50, [%rd135];
	sub.f64 	%fd51, %fd50, %fd49;
	add.f64 	%fd84, %fd84, %fd51;
	st.global.f64 	[%rd185], %fd84;
	add.s32 	%r103, %r103, 1;
	add.s64 	%rd186, %rd186, %rd48;
	add.s32 	%r102, %r102, -1;
	setp.ne.s32 	%p16, %r102, 0;
	@%p16 bra 	$L__BB0_22;

$L__BB0_23:
	not.b32 	%r80, %r106;
	add.s32 	%r81, %r80, %r49;
	sub.s32 	%r82, %r81, %r51;
	setp.lt.u32 	%p17, %r82, 3;
	mov.u32 	%r106, %r103;
	@%p17 bra 	$L__BB0_26;

	shl.b64 	%rd60, %rd44, 5;
	shl.b64 	%rd61, %rd44, 3;
	shl.b64 	%rd62, %rd45, 5;
	shl.b64 	%rd63, %rd45, 3;
	add.s64 	%rd182, %rd185, %rd63;
	add.s64 	%rd137, %rd44, %rd46;
	shl.b64 	%rd138, %rd137, 3;
	add.s64 	%rd183, %rd186, %rd138;
	add.s64 	%rd139, %rd44, %rd47;
	shl.b64 	%rd140, %rd139, 3;
	add.s64 	%rd184, %rd186, %rd140;
	mov.u32 	%r106, %r103;

$L__BB0_25:
	ld.global.f64 	%fd52, [%rd184];
	ld.global.f64 	%fd53, [%rd183];
	sub.f64 	%fd54, %fd53, %fd52;
	add.f64 	%fd55, %fd84, %fd54;
	st.global.f64 	[%rd182], %fd55;
	add.s64 	%rd141, %rd183, %rd61;
	add.s64 	%rd142, %rd184, %rd61;
	ld.global.f64 	%fd56, [%rd142];
	ld.global.f64 	%fd57, [%rd141];
	sub.f64 	%fd58, %fd57, %fd56;
	add.f64 	%fd59, %fd55, %fd58;
	add.s64 	%rd143, %rd182, %rd63;
	st.global.f64 	[%rd143], %fd59;
	add.s64 	%rd144, %rd141, %rd61;
	add.s64 	%rd145, %rd142, %rd61;
	ld.global.f64 	%fd60, [%rd145];
	ld.global.f64 	%fd61, [%rd144];
	sub.f64 	%fd62, %fd61, %fd60;
	add.f64 	%fd63, %fd59, %fd62;
	add.s64 	%rd146, %rd143, %rd63;
	st.global.f64 	[%rd146], %fd63;
	add.s64 	%rd147, %rd144, %rd61;
	add.s64 	%rd183, %rd147, %rd61;
	add.s64 	%rd148, %rd145, %rd61;
	add.s64 	%rd184, %rd148, %rd61;
	ld.global.f64 	%fd64, [%rd148];
	ld.global.f64 	%fd65, [%rd147];
	sub.f64 	%fd66, %fd65, %fd64;
	add.f64 	%fd84, %fd63, %fd66;
	add.s64 	%rd149, %rd146, %rd63;
	add.s64 	%rd182, %rd149, %rd63;
	st.global.f64 	[%rd149], %fd84;
	add.s64 	%rd186, %rd186, %rd60;
	add.s64 	%rd185, %rd185, %rd62;
	add.s32 	%r106, %r106, 4;
	setp.lt.s32 	%p18, %r106, %r27;
	@%p18 bra 	$L__BB0_25;

$L__BB0_26:
	setp.ge.s32 	%p19, %r106, %r49;
	@%p19 bra 	$L__BB0_33;

	cvt.s64.s32 	%rd79, %r48;
	mul.lo.s32 	%r83, %r50, %r48;
	cvt.s64.s32 	%rd80, %r83;
	not.b32 	%r84, %r51;
	mul.lo.s32 	%r85, %r84, %r48;
	cvt.s64.s32 	%rd81, %r85;
	sub.s32 	%r86, %r49, %r106;
	and.b32  	%r108, %r86, 3;
	setp.eq.s32 	%p20, %r108, 0;
	mov.u32 	%r109, %r106;
	@%p20 bra 	$L__BB0_30;

	shl.b64 	%rd82, %rd79, 3;
	shl.b64 	%rd150, %rd81, 3;
	add.s64 	%rd83, %rd82, %rd150;
	shl.b64 	%rd84, %rd80, 3;
	mov.u32 	%r109, %r106;

$L__BB0_29:
	.pragma "nounroll";
	add.s64 	%rd185, %rd185, %rd84;
	add.s64 	%rd151, %rd186, %rd83;
	ld.global.f64 	%fd67, [%rd151];
	sub.f64 	%fd84, %fd84, %fd67;
	st.global.f64 	[%rd185], %fd84;
	add.s32 	%r109, %r109, 1;
	add.s64 	%rd186, %rd186, %rd82;
	add.s32 	%r108, %r108, -1;
	setp.ne.s32 	%p21, %r108, 0;
	@%p21 bra 	$L__BB0_29;

$L__BB0_30:
	not.b32 	%r87, %r106;
	add.s32 	%r88, %r87, %r49;
	setp.lt.u32 	%p22, %r88, 3;
	@%p22 bra 	$L__BB0_33;

	shl.b64 	%rd91, %rd79, 3;
	shl.b64 	%rd93, %rd80, 5;
	add.s64 	%rd194, %rd185, %rd93;
	mul.lo.s64 	%rd152, %rd80, 24;
	add.s64 	%rd193, %rd185, %rd152;
	shl.b64 	%rd153, %rd80, 4;
	add.s64 	%rd192, %rd185, %rd153;
	shl.b64 	%rd154, %rd80, 3;
	add.s64 	%rd191, %rd185, %rd154;
	add.s64 	%rd155, %rd79, %rd81;
	shl.b64 	%rd156, %rd155, 3;
	add.s64 	%rd195, %rd186, %rd156;

$L__BB0_32:
	ld.global.f64 	%fd68, [%rd195];
	sub.f64 	%fd69, %fd84, %fd68;
	st.global.f64 	[%rd191], %fd69;
	add.s64 	%rd157, %rd195, %rd91;
	ld.global.f64 	%fd70, [%rd157];
	sub.f64 	%fd71, %fd69, %fd70;
	st.global.f64 	[%rd192], %fd71;
	add.s64 	%rd158, %rd157, %rd91;
	ld.global.f64 	%fd72, [%rd158];
	sub.f64 	%fd73, %fd71, %fd72;
	st.global.f64 	[%rd193], %fd73;
	add.s64 	%rd159, %rd158, %rd91;
	add.s64 	%rd195, %rd159, %rd91;
	ld.global.f64 	%fd74, [%rd159];
	sub.f64 	%fd84, %fd73, %fd74;
	st.global.f64 	[%rd194], %fd84;
	add.s64 	%rd194, %rd194, %rd93;
	add.s64 	%rd193, %rd193, %rd93;
	add.s64 	%rd192, %rd192, %rd93;
	add.s64 	%rd191, %rd191, %rd93;
	add.s32 	%r109, %r109, 4;
	setp.lt.s32 	%p23, %r109, %r49;
	@%p23 bra 	$L__BB0_32;

$L__BB0_33:
	ret;

}

