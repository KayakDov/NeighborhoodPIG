//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	neighborhoodSum3dKernel

.visible .entry neighborhoodSum3dKernel(
	.param .u32 neighborhoodSum3dKernel_param_0,
	.param .u64 neighborhoodSum3dKernel_param_1,
	.param .u64 neighborhoodSum3dKernel_param_2,
	.param .u32 neighborhoodSum3dKernel_param_3,
	.param .u32 neighborhoodSum3dKernel_param_4,
	.param .u32 neighborhoodSum3dKernel_param_5,
	.param .u32 neighborhoodSum3dKernel_param_6,
	.param .u32 neighborhoodSum3dKernel_param_7,
	.param .u32 neighborhoodSum3dKernel_param_8
)
{
	.reg .pred 	%p<25>;
	.reg .b32 	%r<178>;
	.reg .f64 	%fd<78>;
	.reg .b64 	%rd<196>;


	ld.param.u32 	%r82, [neighborhoodSum3dKernel_param_0];
	ld.param.u64 	%rd105, [neighborhoodSum3dKernel_param_1];
	ld.param.u64 	%rd106, [neighborhoodSum3dKernel_param_2];
	ld.param.u32 	%r76, [neighborhoodSum3dKernel_param_3];
	ld.param.u32 	%r77, [neighborhoodSum3dKernel_param_4];
	ld.param.u32 	%r138, [neighborhoodSum3dKernel_param_5];
	ld.param.u32 	%r79, [neighborhoodSum3dKernel_param_6];
	ld.param.u32 	%r80, [neighborhoodSum3dKernel_param_7];
	ld.param.u32 	%r81, [neighborhoodSum3dKernel_param_8];
	cvta.to.global.u64 	%rd1, %rd106;
	cvta.to.global.u64 	%rd2, %rd105;
	mov.u32 	%r83, %ntid.x;
	mov.u32 	%r84, %ctaid.x;
	mov.u32 	%r85, %tid.x;
	mad.lo.s32 	%r136, %r84, %r83, %r85;
	setp.ge.s32 	%p1, %r136, %r82;
	@%p1 bra 	$L__BB0_35;

	setp.eq.s32 	%p2, %r81, 0;
	@%p2 bra 	$L__BB0_6;

	setp.eq.s32 	%p3, %r81, 1;
	@%p3 bra 	$L__BB0_5;

	setp.ne.s32 	%p4, %r81, 2;
	@%p4 bra 	$L__BB0_7;

	mul.lo.s32 	%r137, %r77, %r76;
	bra.uni 	$L__BB0_7;

$L__BB0_6:
	div.s32 	%r88, %r136, %r76;
	mul.lo.s32 	%r89, %r88, %r76;
	sub.s32 	%r90, %r136, %r89;
	mul.lo.s32 	%r91, %r77, %r76;
	mad.lo.s32 	%r136, %r91, %r88, %r90;
	mov.u32 	%r137, %r76;
	mov.u32 	%r138, %r77;
	bra.uni 	$L__BB0_7;

$L__BB0_5:
	mul.lo.s32 	%r136, %r136, %r76;
	mov.u32 	%r137, 1;
	mov.u32 	%r138, %r76;

$L__BB0_7:
	cvt.s64.s32 	%rd3, %r136;
	mul.wide.s32 	%rd107, %r136, 8;
	add.s64 	%rd186, %rd2, %rd107;
	mul.lo.s32 	%r93, %r136, %r79;
	cvt.s64.s32 	%rd5, %r93;
	setp.lt.s32 	%p5, %r80, 0;
	mov.u32 	%r158, 0;
	@%p5 bra 	$L__BB0_14;

	add.s32 	%r8, %r80, 1;
	and.b32  	%r146, %r8, 3;
	setp.lt.u32 	%p6, %r80, 3;
	mov.u32 	%r143, 0;
	mov.u32 	%r158, %r143;
	@%p6 bra 	$L__BB0_11;

	sub.s32 	%r141, %r8, %r146;
	mul.wide.s32 	%rd6, %r137, 8;

$L__BB0_10:
	mul.lo.s32 	%r99, %r143, %r137;
	mul.wide.s32 	%rd108, %r99, 8;
	add.s64 	%rd109, %rd186, %rd108;
	cvt.rn.f64.s32 	%fd1, %r158;
	ld.global.f64 	%fd2, [%rd109];
	add.f64 	%fd3, %fd2, %fd1;
	cvt.rzi.s32.f64 	%r100, %fd3;
	add.s64 	%rd110, %rd109, %rd6;
	cvt.rn.f64.s32 	%fd4, %r100;
	ld.global.f64 	%fd5, [%rd110];
	add.f64 	%fd6, %fd5, %fd4;
	cvt.rzi.s32.f64 	%r101, %fd6;
	add.s64 	%rd111, %rd110, %rd6;
	cvt.rn.f64.s32 	%fd7, %r101;
	ld.global.f64 	%fd8, [%rd111];
	add.f64 	%fd9, %fd8, %fd7;
	cvt.rzi.s32.f64 	%r102, %fd9;
	add.s64 	%rd112, %rd111, %rd6;
	cvt.rn.f64.s32 	%fd10, %r102;
	ld.global.f64 	%fd11, [%rd112];
	add.f64 	%fd12, %fd11, %fd10;
	cvt.rzi.s32.f64 	%r158, %fd12;
	add.s32 	%r143, %r143, 4;
	add.s32 	%r141, %r141, -4;
	setp.ne.s32 	%p7, %r141, 0;
	@%p7 bra 	$L__BB0_10;

$L__BB0_11:
	setp.eq.s32 	%p8, %r146, 0;
	@%p8 bra 	$L__BB0_14;

	mul.lo.s32 	%r103, %r137, %r143;
	cvt.s64.s32 	%rd113, %r103;
	add.s64 	%rd114, %rd3, %rd113;
	shl.b64 	%rd115, %rd114, 3;
	add.s64 	%rd161, %rd2, %rd115;
	mul.wide.s32 	%rd8, %r137, 8;

$L__BB0_13:
	.pragma "nounroll";
	cvt.rn.f64.s32 	%fd13, %r158;
	ld.global.f64 	%fd14, [%rd161];
	add.f64 	%fd15, %fd14, %fd13;
	cvt.rzi.s32.f64 	%r158, %fd15;
	add.s64 	%rd161, %rd161, %rd8;
	add.s32 	%r146, %r146, -1;
	setp.ne.s32 	%p9, %r146, 0;
	@%p9 bra 	$L__BB0_13;

$L__BB0_14:
	shl.b64 	%rd116, %rd5, 3;
	add.s64 	%rd185, %rd1, %rd116;
	cvt.rn.f64.s32 	%fd16, %r158;
	st.global.f64 	[%rd185], %fd16;
	setp.lt.s32 	%p10, %r80, 1;
	mov.u32 	%r170, 1;
	@%p10 bra 	$L__BB0_21;

	cvt.s64.s32 	%rd12, %r137;
	mul.lo.s32 	%r107, %r137, %r79;
	cvt.s64.s32 	%rd13, %r107;
	mul.lo.s32 	%r108, %r137, %r80;
	cvt.s64.s32 	%rd14, %r108;
	and.b32  	%r157, %r80, 3;
	add.s32 	%r109, %r80, -1;
	setp.lt.u32 	%p11, %r109, 3;
	mov.u32 	%r170, 1;
	@%p11 bra 	$L__BB0_18;

	sub.s32 	%r150, %r80, %r157;
	shl.b64 	%rd15, %rd12, 2;
	add.s64 	%rd118, %rd13, %rd5;
	shl.b64 	%rd119, %rd118, 3;
	add.s64 	%rd164, %rd1, %rd119;
	shl.b64 	%rd17, %rd13, 3;
	add.s64 	%rd120, %rd3, %rd12;
	add.s64 	%rd121, %rd120, %rd14;
	shl.b64 	%rd122, %rd121, 3;
	add.s64 	%rd165, %rd2, %rd122;
	shl.b64 	%rd19, %rd12, 3;
	shl.b64 	%rd127, %rd15, 3;

$L__BB0_17:
	cvt.rn.f64.s32 	%fd17, %r158;
	ld.global.f64 	%fd18, [%rd165];
	add.f64 	%fd19, %fd18, %fd17;
	cvt.rzi.s32.f64 	%r111, %fd19;
	cvt.rn.f64.s32 	%fd20, %r111;
	st.global.f64 	[%rd164], %fd20;
	add.s64 	%rd123, %rd165, %rd19;
	ld.global.f64 	%fd21, [%rd123];
	add.f64 	%fd22, %fd21, %fd20;
	cvt.rzi.s32.f64 	%r112, %fd22;
	cvt.rn.f64.s32 	%fd23, %r112;
	add.s64 	%rd124, %rd164, %rd17;
	st.global.f64 	[%rd124], %fd23;
	add.s64 	%rd125, %rd123, %rd19;
	ld.global.f64 	%fd24, [%rd125];
	add.f64 	%fd25, %fd24, %fd23;
	cvt.rzi.s32.f64 	%r113, %fd25;
	cvt.rn.f64.s32 	%fd26, %r113;
	add.s64 	%rd126, %rd124, %rd17;
	st.global.f64 	[%rd126], %fd26;
	add.s64 	%rd186, %rd186, %rd127;
	shl.b64 	%rd128, %rd13, 5;
	add.s64 	%rd185, %rd185, %rd128;
	add.s64 	%rd129, %rd125, %rd19;
	add.s64 	%rd165, %rd129, %rd19;
	ld.global.f64 	%fd27, [%rd129];
	add.f64 	%fd28, %fd27, %fd26;
	cvt.rzi.s32.f64 	%r158, %fd28;
	cvt.rn.f64.s32 	%fd29, %r158;
	add.s64 	%rd130, %rd126, %rd17;
	add.s64 	%rd164, %rd130, %rd17;
	st.global.f64 	[%rd130], %fd29;
	add.s32 	%r170, %r170, 4;
	add.s32 	%r150, %r150, -4;
	setp.ne.s32 	%p12, %r150, 0;
	@%p12 bra 	$L__BB0_17;

$L__BB0_18:
	setp.eq.s32 	%p13, %r157, 0;
	@%p13 bra 	$L__BB0_21;

	shl.b64 	%rd32, %rd12, 3;
	shl.b64 	%rd131, %rd14, 3;
	add.s64 	%rd33, %rd32, %rd131;
	shl.b64 	%rd34, %rd13, 3;

$L__BB0_20:
	.pragma "nounroll";
	add.s64 	%rd185, %rd185, %rd34;
	add.s64 	%rd132, %rd186, %rd33;
	cvt.rn.f64.s32 	%fd30, %r158;
	ld.global.f64 	%fd31, [%rd132];
	add.f64 	%fd32, %fd31, %fd30;
	cvt.rzi.s32.f64 	%r158, %fd32;
	cvt.rn.f64.s32 	%fd33, %r158;
	st.global.f64 	[%rd185], %fd33;
	add.s32 	%r170, %r170, 1;
	add.s64 	%rd186, %rd186, %rd32;
	add.s32 	%r157, %r157, -1;
	setp.ne.s32 	%p14, %r157, 0;
	@%p14 bra 	$L__BB0_20;

$L__BB0_21:
	sub.s32 	%r45, %r138, %r80;
	setp.ge.s32 	%p15, %r170, %r45;
	@%p15 bra 	$L__BB0_28;

	cvt.s64.s32 	%rd41, %r137;
	mul.lo.s32 	%r115, %r137, %r79;
	cvt.s64.s32 	%rd42, %r115;
	mul.lo.s32 	%r116, %r137, %r80;
	cvt.s64.s32 	%rd43, %r116;
	not.b32 	%r117, %r80;
	mul.lo.s32 	%r118, %r137, %r117;
	cvt.s64.s32 	%rd44, %r118;
	sub.s32 	%r119, %r138, %r170;
	sub.s32 	%r120, %r119, %r80;
	and.b32  	%r162, %r120, 3;
	setp.eq.s32 	%p16, %r162, 0;
	mov.u32 	%r163, %r170;
	@%p16 bra 	$L__BB0_25;

	shl.b64 	%rd45, %rd41, 3;
	shl.b64 	%rd134, %rd44, 3;
	add.s64 	%rd46, %rd45, %rd134;
	shl.b64 	%rd135, %rd43, 3;
	add.s64 	%rd47, %rd45, %rd135;
	shl.b64 	%rd48, %rd42, 3;
	mov.u32 	%r163, %r170;

$L__BB0_24:
	.pragma "nounroll";
	add.s64 	%rd185, %rd185, %rd48;
	add.s64 	%rd136, %rd186, %rd47;
	add.s64 	%rd137, %rd186, %rd46;
	ld.global.f64 	%fd34, [%rd137];
	ld.global.f64 	%fd35, [%rd136];
	sub.f64 	%fd36, %fd35, %fd34;
	cvt.rn.f64.s32 	%fd37, %r158;
	add.f64 	%fd38, %fd36, %fd37;
	cvt.rzi.s32.f64 	%r158, %fd38;
	cvt.rn.f64.s32 	%fd39, %r158;
	st.global.f64 	[%rd185], %fd39;
	add.s32 	%r163, %r163, 1;
	add.s64 	%rd186, %rd186, %rd45;
	add.s32 	%r162, %r162, -1;
	setp.ne.s32 	%p17, %r162, 0;
	@%p17 bra 	$L__BB0_24;

$L__BB0_25:
	not.b32 	%r121, %r170;
	add.s32 	%r122, %r138, %r121;
	sub.s32 	%r123, %r122, %r80;
	setp.lt.u32 	%p18, %r123, 3;
	mov.u32 	%r170, %r163;
	@%p18 bra 	$L__BB0_28;

	shl.b64 	%rd57, %rd41, 5;
	shl.b64 	%rd58, %rd41, 3;
	shl.b64 	%rd59, %rd42, 5;
	shl.b64 	%rd60, %rd42, 3;
	add.s64 	%rd182, %rd185, %rd60;
	add.s64 	%rd138, %rd41, %rd43;
	shl.b64 	%rd139, %rd138, 3;
	add.s64 	%rd183, %rd186, %rd139;
	add.s64 	%rd140, %rd41, %rd44;
	shl.b64 	%rd141, %rd140, 3;
	add.s64 	%rd184, %rd186, %rd141;
	mov.u32 	%r170, %r163;

$L__BB0_27:
	ld.global.f64 	%fd40, [%rd184];
	ld.global.f64 	%fd41, [%rd183];
	sub.f64 	%fd42, %fd41, %fd40;
	cvt.rn.f64.s32 	%fd43, %r158;
	add.f64 	%fd44, %fd42, %fd43;
	cvt.rzi.s32.f64 	%r124, %fd44;
	cvt.rn.f64.s32 	%fd45, %r124;
	st.global.f64 	[%rd182], %fd45;
	add.s64 	%rd142, %rd183, %rd58;
	add.s64 	%rd143, %rd184, %rd58;
	ld.global.f64 	%fd46, [%rd143];
	ld.global.f64 	%fd47, [%rd142];
	sub.f64 	%fd48, %fd47, %fd46;
	add.f64 	%fd49, %fd48, %fd45;
	cvt.rzi.s32.f64 	%r125, %fd49;
	cvt.rn.f64.s32 	%fd50, %r125;
	add.s64 	%rd144, %rd182, %rd60;
	st.global.f64 	[%rd144], %fd50;
	add.s64 	%rd145, %rd142, %rd58;
	add.s64 	%rd146, %rd143, %rd58;
	ld.global.f64 	%fd51, [%rd146];
	ld.global.f64 	%fd52, [%rd145];
	sub.f64 	%fd53, %fd52, %fd51;
	add.f64 	%fd54, %fd53, %fd50;
	cvt.rzi.s32.f64 	%r126, %fd54;
	cvt.rn.f64.s32 	%fd55, %r126;
	add.s64 	%rd147, %rd144, %rd60;
	st.global.f64 	[%rd147], %fd55;
	add.s64 	%rd148, %rd145, %rd58;
	add.s64 	%rd183, %rd148, %rd58;
	add.s64 	%rd149, %rd146, %rd58;
	add.s64 	%rd184, %rd149, %rd58;
	ld.global.f64 	%fd56, [%rd149];
	ld.global.f64 	%fd57, [%rd148];
	sub.f64 	%fd58, %fd57, %fd56;
	add.f64 	%fd59, %fd58, %fd55;
	cvt.rzi.s32.f64 	%r158, %fd59;
	cvt.rn.f64.s32 	%fd60, %r158;
	add.s64 	%rd150, %rd147, %rd60;
	add.s64 	%rd182, %rd150, %rd60;
	st.global.f64 	[%rd150], %fd60;
	add.s64 	%rd186, %rd186, %rd57;
	add.s64 	%rd185, %rd185, %rd59;
	add.s32 	%r170, %r170, 4;
	setp.lt.s32 	%p19, %r170, %r45;
	@%p19 bra 	$L__BB0_27;

$L__BB0_28:
	setp.le.s32 	%p20, %r138, %r170;
	@%p20 bra 	$L__BB0_35;

	cvt.s64.s32 	%rd76, %r137;
	mul.lo.s32 	%r127, %r137, %r79;
	cvt.s64.s32 	%rd77, %r127;
	not.b32 	%r128, %r80;
	mul.lo.s32 	%r129, %r137, %r128;
	cvt.s64.s32 	%rd78, %r129;
	sub.s32 	%r130, %r138, %r170;
	and.b32  	%r173, %r130, 3;
	setp.eq.s32 	%p21, %r173, 0;
	mov.u32 	%r174, %r170;
	@%p21 bra 	$L__BB0_32;

	shl.b64 	%rd79, %rd76, 3;
	shl.b64 	%rd151, %rd78, 3;
	add.s64 	%rd80, %rd79, %rd151;
	shl.b64 	%rd81, %rd77, 3;
	mov.u32 	%r174, %r170;

$L__BB0_31:
	.pragma "nounroll";
	add.s64 	%rd185, %rd185, %rd81;
	add.s64 	%rd152, %rd186, %rd80;
	cvt.rn.f64.s32 	%fd61, %r158;
	ld.global.f64 	%fd62, [%rd152];
	sub.f64 	%fd63, %fd61, %fd62;
	cvt.rzi.s32.f64 	%r158, %fd63;
	cvt.rn.f64.s32 	%fd64, %r158;
	st.global.f64 	[%rd185], %fd64;
	add.s32 	%r174, %r174, 1;
	add.s64 	%rd186, %rd186, %rd79;
	add.s32 	%r173, %r173, -1;
	setp.ne.s32 	%p22, %r173, 0;
	@%p22 bra 	$L__BB0_31;

$L__BB0_32:
	not.b32 	%r131, %r170;
	add.s32 	%r132, %r138, %r131;
	setp.lt.u32 	%p23, %r132, 3;
	@%p23 bra 	$L__BB0_35;

	shl.b64 	%rd88, %rd76, 3;
	shl.b64 	%rd90, %rd77, 5;
	add.s64 	%rd194, %rd185, %rd90;
	mul.lo.s64 	%rd153, %rd77, 24;
	add.s64 	%rd193, %rd185, %rd153;
	shl.b64 	%rd154, %rd77, 4;
	add.s64 	%rd192, %rd185, %rd154;
	shl.b64 	%rd155, %rd77, 3;
	add.s64 	%rd191, %rd185, %rd155;
	add.s64 	%rd156, %rd76, %rd78;
	shl.b64 	%rd157, %rd156, 3;
	add.s64 	%rd195, %rd186, %rd157;

$L__BB0_34:
	cvt.rn.f64.s32 	%fd65, %r158;
	ld.global.f64 	%fd66, [%rd195];
	sub.f64 	%fd67, %fd65, %fd66;
	cvt.rzi.s32.f64 	%r133, %fd67;
	cvt.rn.f64.s32 	%fd68, %r133;
	st.global.f64 	[%rd191], %fd68;
	add.s64 	%rd158, %rd195, %rd88;
	ld.global.f64 	%fd69, [%rd158];
	sub.f64 	%fd70, %fd68, %fd69;
	cvt.rzi.s32.f64 	%r134, %fd70;
	cvt.rn.f64.s32 	%fd71, %r134;
	st.global.f64 	[%rd192], %fd71;
	add.s64 	%rd159, %rd158, %rd88;
	ld.global.f64 	%fd72, [%rd159];
	sub.f64 	%fd73, %fd71, %fd72;
	cvt.rzi.s32.f64 	%r135, %fd73;
	cvt.rn.f64.s32 	%fd74, %r135;
	st.global.f64 	[%rd193], %fd74;
	add.s64 	%rd160, %rd159, %rd88;
	add.s64 	%rd195, %rd160, %rd88;
	ld.global.f64 	%fd75, [%rd160];
	sub.f64 	%fd76, %fd74, %fd75;
	cvt.rzi.s32.f64 	%r158, %fd76;
	cvt.rn.f64.s32 	%fd77, %r158;
	st.global.f64 	[%rd194], %fd77;
	add.s64 	%rd194, %rd194, %rd90;
	add.s64 	%rd193, %rd193, %rd90;
	add.s64 	%rd192, %rd192, %rd90;
	add.s64 	%rd191, %rd191, %rd90;
	add.s32 	%r174, %r174, 4;
	setp.lt.s32 	%p24, %r174, %r138;
	@%p24 bra 	$L__BB0_34;

$L__BB0_35:
	ret;

}

