//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	eigenVecBatch3x3Kernel
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str$1[2] = {10, 0};
.global .align 1 .b8 $str$2[15] = {84, 104, 114, 101, 97, 100, 32, 105, 100, 58, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str$3[8] = {37, 49, 48, 46, 52, 102, 32, 0};

.visible .entry eigenVecBatch3x3Kernel(
	.param .u32 eigenVecBatch3x3Kernel_param_0,
	.param .u64 eigenVecBatch3x3Kernel_param_1,
	.param .u32 eigenVecBatch3x3Kernel_param_2,
	.param .u64 eigenVecBatch3x3Kernel_param_3,
	.param .u32 eigenVecBatch3x3Kernel_param_4,
	.param .u64 eigenVecBatch3x3Kernel_param_5,
	.param .u64 eigenVecBatch3x3Kernel_param_6,
	.param .f64 eigenVecBatch3x3Kernel_param_7
)
{
	.local .align 8 .b8 	__local_depot0[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<43>;
	.reg .b32 	%r<88>;
	.reg .f64 	%fd<198>;
	.reg .b64 	%rd<57>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r25, [eigenVecBatch3x3Kernel_param_0];
	ld.param.u64 	%rd7, [eigenVecBatch3x3Kernel_param_1];
	ld.param.u64 	%rd8, [eigenVecBatch3x3Kernel_param_3];
	ld.param.u32 	%r24, [eigenVecBatch3x3Kernel_param_4];
	ld.param.u64 	%rd9, [eigenVecBatch3x3Kernel_param_5];
	ld.param.u64 	%rd10, [eigenVecBatch3x3Kernel_param_6];
	ld.param.f64 	%fd15, [eigenVecBatch3x3Kernel_param_7];
	mov.u32 	%r26, %ntid.x;
	mov.u32 	%r27, %ctaid.x;
	mov.u32 	%r28, %tid.x;
	mad.lo.s32 	%r1, %r27, %r26, %r28;
	setp.ge.s32 	%p1, %r1, %r25;
	@%p1 bra 	$L__BB0_41;

	cvta.to.global.u64 	%rd11, %rd10;
	mul.lo.s32 	%r31, %r1, 9;
	cvta.to.global.u64 	%rd12, %rd7;
	mul.wide.s32 	%rd13, %r31, 8;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.f64 	%fd16, [%rd14];
	add.s64 	%rd1, %rd11, %rd13;
	st.global.f64 	[%rd1], %fd16;
	ld.global.f64 	%fd17, [%rd14+8];
	st.global.f64 	[%rd1+24], %fd17;
	ld.global.f64 	%fd18, [%rd14+16];
	st.global.f64 	[%rd1+48], %fd18;
	ld.global.f64 	%fd19, [%rd14+24];
	add.s64 	%rd2, %rd1, 8;
	st.global.f64 	[%rd1+8], %fd19;
	ld.global.f64 	%fd20, [%rd14+32];
	st.global.f64 	[%rd1+32], %fd20;
	ld.global.f64 	%fd21, [%rd14+40];
	st.global.f64 	[%rd1+56], %fd21;
	ld.global.f64 	%fd22, [%rd14+48];
	st.global.f64 	[%rd1+16], %fd22;
	ld.global.f64 	%fd23, [%rd14+56];
	st.global.f64 	[%rd1+40], %fd23;
	ld.global.f64 	%fd24, [%rd14+64];
	st.global.f64 	[%rd1+64], %fd24;
	cvta.to.global.u64 	%rd15, %rd9;
	mul.wide.s32 	%rd16, %r1, 8;
	add.s64 	%rd17, %rd15, %rd16;
	ld.global.f64 	%fd25, [%rd17];
	sub.f64 	%fd26, %fd16, %fd25;
	st.global.f64 	[%rd1], %fd26;
	ld.global.f64 	%fd27, [%rd17];
	sub.f64 	%fd28, %fd20, %fd27;
	st.global.f64 	[%rd1+32], %fd28;
	ld.global.f64 	%fd29, [%rd17];
	sub.f64 	%fd30, %fd24, %fd29;
	st.global.f64 	[%rd1+64], %fd30;
	mul.lo.s32 	%r32, %r1, %r24;
	cvta.to.global.u64 	%rd18, %rd8;
	mul.wide.s32 	%rd19, %r32, 8;
	add.s64 	%rd3, %rd18, %rd19;
	add.u64 	%rd20, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	mov.u32 	%r80, 0;
	mov.u32 	%r81, %r80;

$L__BB0_2:
	add.s32 	%r33, %r80, %r81;
	mul.wide.s32 	%rd21, %r33, 8;
	add.s64 	%rd5, %rd1, %rd21;
	ld.global.f64 	%fd197, [%rd5];
	abs.f64 	%fd195, %fd197;
	setp.gt.u32 	%p2, %r81, 1;
	mov.u32 	%r84, %r81;
	@%p2 bra 	$L__BB0_9;

	mov.u32 	%r35, 2;
	sub.s32 	%r36, %r35, %r81;
	and.b32  	%r4, %r36, 3;
	setp.eq.s32 	%p3, %r4, 0;
	mov.u32 	%r82, %r81;
	mov.u32 	%r84, %r81;
	@%p3 bra 	$L__BB0_7;

	add.s32 	%r82, %r81, 1;
	ld.global.f64 	%fd32, [%rd5+8];
	abs.f64 	%fd33, %fd32;
	setp.gt.f64 	%p4, %fd33, %fd195;
	selp.f64 	%fd195, %fd33, %fd195, %p4;
	selp.b32 	%r84, %r82, %r81, %p4;
	setp.eq.s32 	%p5, %r4, 1;
	@%p5 bra 	$L__BB0_7;

	add.s32 	%r82, %r81, 2;
	ld.global.f64 	%fd34, [%rd5+16];
	abs.f64 	%fd35, %fd34;
	setp.gt.f64 	%p6, %fd35, %fd195;
	selp.f64 	%fd195, %fd35, %fd195, %p6;
	selp.b32 	%r84, %r82, %r84, %p6;
	setp.eq.s32 	%p7, %r4, 2;
	@%p7 bra 	$L__BB0_7;

	add.s32 	%r82, %r81, 3;
	ld.global.f64 	%fd36, [%rd5+24];
	abs.f64 	%fd37, %fd36;
	setp.gt.f64 	%p8, %fd37, %fd195;
	selp.f64 	%fd195, %fd37, %fd195, %p8;
	selp.b32 	%r84, %r82, %r84, %p8;

$L__BB0_7:
	mov.u32 	%r37, 1;
	sub.s32 	%r38, %r37, %r81;
	setp.lt.u32 	%p9, %r38, 3;
	@%p9 bra 	$L__BB0_9;

	add.s32 	%r39, %r82, 1;
	add.s32 	%r40, %r39, %r80;
	mul.wide.s32 	%rd22, %r40, 8;
	add.s64 	%rd23, %rd1, %rd22;
	ld.global.f64 	%fd38, [%rd23];
	abs.f64 	%fd39, %fd38;
	setp.gt.f64 	%p10, %fd39, %fd195;
	selp.f64 	%fd40, %fd39, %fd195, %p10;
	selp.b32 	%r41, %r39, %r84, %p10;
	ld.global.f64 	%fd41, [%rd23+8];
	abs.f64 	%fd42, %fd41;
	setp.gt.f64 	%p11, %fd42, %fd40;
	selp.f64 	%fd43, %fd42, %fd40, %p11;
	add.s32 	%r42, %r82, 2;
	selp.b32 	%r43, %r42, %r41, %p11;
	ld.global.f64 	%fd44, [%rd23+16];
	abs.f64 	%fd45, %fd44;
	setp.gt.f64 	%p12, %fd45, %fd43;
	selp.f64 	%fd46, %fd45, %fd43, %p12;
	add.s32 	%r44, %r82, 3;
	selp.b32 	%r45, %r44, %r43, %p12;
	ld.global.f64 	%fd47, [%rd23+24];
	abs.f64 	%fd48, %fd47;
	setp.gt.f64 	%p13, %fd48, %fd46;
	selp.f64 	%fd195, %fd48, %fd46, %p13;
	add.s32 	%r46, %r82, 4;
	selp.b32 	%r84, %r46, %r45, %p13;

$L__BB0_9:
	setp.le.f64 	%p14, %fd195, %fd15;
	setp.eq.s32 	%p15, %r84, -1;
	or.pred  	%p16, %p14, %p15;
	mov.u32 	%r87, 0;
	@%p16 bra 	$L__BB0_19;

	setp.eq.s32 	%p17, %r84, %r81;
	mul.wide.s32 	%rd24, %r81, 8;
	add.s64 	%rd6, %rd1, %rd24;
	@%p17 bra 	$L__BB0_12;

	mul.wide.s32 	%rd25, %r84, 8;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.f64 	%fd49, [%rd6];
	ld.global.f64 	%fd50, [%rd26];
	st.global.f64 	[%rd6], %fd50;
	st.global.f64 	[%rd26], %fd49;
	ld.global.f64 	%fd51, [%rd6+24];
	ld.global.f64 	%fd52, [%rd26+24];
	st.global.f64 	[%rd6+24], %fd52;
	st.global.f64 	[%rd26+24], %fd51;
	ld.global.f64 	%fd53, [%rd6+48];
	ld.global.f64 	%fd54, [%rd26+48];
	st.global.f64 	[%rd6+48], %fd54;
	st.global.f64 	[%rd26+48], %fd53;
	ld.global.f64 	%fd197, [%rd5];

$L__BB0_12:
	mov.u32 	%r87, 1;
	@%p2 bra 	$L__BB0_19;

	mov.u32 	%r49, 2;
	sub.s32 	%r50, %r49, %r81;
	and.b32  	%r16, %r50, 3;
	setp.eq.s32 	%p19, %r16, 0;
	mov.u32 	%r86, %r81;
	@%p19 bra 	$L__BB0_17;

	add.s32 	%r86, %r81, 1;
	ld.global.f64 	%fd55, [%rd5+8];
	div.rn.f64 	%fd56, %fd55, %fd197;
	ld.global.f64 	%fd57, [%rd6];
	mul.f64 	%fd58, %fd56, %fd57;
	ld.global.f64 	%fd59, [%rd6+8];
	sub.f64 	%fd60, %fd59, %fd58;
	st.global.f64 	[%rd6+8], %fd60;
	ld.global.f64 	%fd61, [%rd6+24];
	mul.f64 	%fd62, %fd56, %fd61;
	ld.global.f64 	%fd63, [%rd6+32];
	sub.f64 	%fd64, %fd63, %fd62;
	st.global.f64 	[%rd6+32], %fd64;
	ld.global.f64 	%fd65, [%rd6+48];
	mul.f64 	%fd66, %fd56, %fd65;
	ld.global.f64 	%fd67, [%rd6+56];
	sub.f64 	%fd68, %fd67, %fd66;
	st.global.f64 	[%rd6+56], %fd68;
	setp.eq.s32 	%p20, %r16, 1;
	@%p20 bra 	$L__BB0_17;

	add.s32 	%r86, %r81, 2;
	ld.global.f64 	%fd69, [%rd5+16];
	div.rn.f64 	%fd70, %fd69, %fd197;
	ld.global.f64 	%fd71, [%rd6];
	mul.f64 	%fd72, %fd70, %fd71;
	ld.global.f64 	%fd73, [%rd6+16];
	sub.f64 	%fd74, %fd73, %fd72;
	st.global.f64 	[%rd6+16], %fd74;
	ld.global.f64 	%fd75, [%rd6+24];
	mul.f64 	%fd76, %fd70, %fd75;
	ld.global.f64 	%fd77, [%rd6+40];
	sub.f64 	%fd78, %fd77, %fd76;
	st.global.f64 	[%rd6+40], %fd78;
	ld.global.f64 	%fd79, [%rd6+48];
	mul.f64 	%fd80, %fd70, %fd79;
	ld.global.f64 	%fd81, [%rd6+64];
	sub.f64 	%fd82, %fd81, %fd80;
	st.global.f64 	[%rd6+64], %fd82;
	setp.eq.s32 	%p21, %r16, 2;
	@%p21 bra 	$L__BB0_17;

	add.s32 	%r86, %r81, 3;
	ld.global.f64 	%fd83, [%rd5+24];
	div.rn.f64 	%fd84, %fd83, %fd197;
	ld.global.f64 	%fd85, [%rd6];
	mul.f64 	%fd86, %fd84, %fd85;
	ld.global.f64 	%fd87, [%rd6+24];
	sub.f64 	%fd88, %fd87, %fd86;
	st.global.f64 	[%rd6+24], %fd88;
	mul.f64 	%fd89, %fd84, %fd88;
	ld.global.f64 	%fd90, [%rd6+48];
	sub.f64 	%fd91, %fd90, %fd89;
	st.global.f64 	[%rd6+48], %fd91;
	mul.f64 	%fd92, %fd84, %fd91;
	ld.global.f64 	%fd93, [%rd6+72];
	sub.f64 	%fd94, %fd93, %fd92;
	st.global.f64 	[%rd6+72], %fd94;

$L__BB0_17:
	mov.u32 	%r87, 1;
	sub.s32 	%r52, %r87, %r81;
	setp.lt.u32 	%p22, %r52, 3;
	@%p22 bra 	$L__BB0_19;

	add.s32 	%r54, %r86, %r80;
	add.s32 	%r55, %r54, 1;
	mul.wide.s32 	%rd27, %r55, 8;
	add.s64 	%rd28, %rd1, %rd27;
	ld.global.f64 	%fd95, [%rd28];
	div.rn.f64 	%fd96, %fd95, %fd197;
	ld.global.f64 	%fd97, [%rd6];
	mul.f64 	%fd98, %fd96, %fd97;
	mul.wide.s32 	%rd29, %r86, 8;
	add.s64 	%rd30, %rd2, %rd29;
	ld.global.f64 	%fd99, [%rd30];
	sub.f64 	%fd100, %fd99, %fd98;
	st.global.f64 	[%rd30], %fd100;
	ld.global.f64 	%fd101, [%rd6+24];
	mul.f64 	%fd102, %fd96, %fd101;
	ld.global.f64 	%fd103, [%rd30+24];
	sub.f64 	%fd104, %fd103, %fd102;
	st.global.f64 	[%rd30+24], %fd104;
	ld.global.f64 	%fd105, [%rd6+48];
	mul.f64 	%fd106, %fd96, %fd105;
	ld.global.f64 	%fd107, [%rd30+48];
	sub.f64 	%fd108, %fd107, %fd106;
	st.global.f64 	[%rd30+48], %fd108;
	ld.global.f64 	%fd109, [%rd28+8];
	div.rn.f64 	%fd110, %fd109, %fd197;
	ld.global.f64 	%fd111, [%rd6];
	mul.f64 	%fd112, %fd110, %fd111;
	ld.global.f64 	%fd113, [%rd30+8];
	sub.f64 	%fd114, %fd113, %fd112;
	st.global.f64 	[%rd30+8], %fd114;
	ld.global.f64 	%fd115, [%rd6+24];
	mul.f64 	%fd116, %fd110, %fd115;
	ld.global.f64 	%fd117, [%rd30+32];
	sub.f64 	%fd118, %fd117, %fd116;
	st.global.f64 	[%rd30+32], %fd118;
	ld.global.f64 	%fd119, [%rd6+48];
	mul.f64 	%fd120, %fd110, %fd119;
	ld.global.f64 	%fd121, [%rd30+56];
	sub.f64 	%fd122, %fd121, %fd120;
	st.global.f64 	[%rd30+56], %fd122;
	ld.global.f64 	%fd123, [%rd28+16];
	div.rn.f64 	%fd124, %fd123, %fd197;
	ld.global.f64 	%fd125, [%rd6];
	mul.f64 	%fd126, %fd124, %fd125;
	ld.global.f64 	%fd127, [%rd30+16];
	sub.f64 	%fd128, %fd127, %fd126;
	st.global.f64 	[%rd30+16], %fd128;
	ld.global.f64 	%fd129, [%rd6+24];
	mul.f64 	%fd130, %fd124, %fd129;
	ld.global.f64 	%fd131, [%rd30+40];
	sub.f64 	%fd132, %fd131, %fd130;
	st.global.f64 	[%rd30+40], %fd132;
	ld.global.f64 	%fd133, [%rd6+48];
	mul.f64 	%fd134, %fd124, %fd133;
	ld.global.f64 	%fd135, [%rd30+64];
	sub.f64 	%fd136, %fd135, %fd134;
	st.global.f64 	[%rd30+64], %fd136;
	ld.global.f64 	%fd137, [%rd28+24];
	div.rn.f64 	%fd138, %fd137, %fd197;
	ld.global.f64 	%fd139, [%rd6];
	mul.f64 	%fd140, %fd138, %fd139;
	ld.global.f64 	%fd141, [%rd30+24];
	sub.f64 	%fd142, %fd141, %fd140;
	st.global.f64 	[%rd30+24], %fd142;
	ld.global.f64 	%fd143, [%rd6+24];
	mul.f64 	%fd144, %fd138, %fd143;
	ld.global.f64 	%fd145, [%rd30+48];
	sub.f64 	%fd146, %fd145, %fd144;
	st.global.f64 	[%rd30+48], %fd146;
	ld.global.f64 	%fd147, [%rd6+48];
	mul.f64 	%fd148, %fd138, %fd147;
	ld.global.f64 	%fd149, [%rd30+72];
	sub.f64 	%fd150, %fd149, %fd148;
	st.global.f64 	[%rd30+72], %fd150;

$L__BB0_19:
	add.s32 	%r81, %r87, %r81;
	add.s32 	%r80, %r80, 3;
	setp.lt.u32 	%p23, %r80, 9;
	@%p23 bra 	$L__BB0_2;

	setp.ne.s32 	%p24, %r1, 1;
	@%p24 bra 	$L__BB0_22;

	mov.u64 	%rd31, $str$1;
	cvta.global.u64 	%rd32, %rd31;
	mov.u32 	%r56, 1;
	mov.u64 	%rd33, 0;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r57, [retval0+0];
	} // callseq 0
	st.local.u32 	[%rd4], %r56;
	mov.u64 	%rd34, $str$2;
	cvta.global.u64 	%rd35, %rd34;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r58, [retval0+0];
	} // callseq 1
	ld.global.f64 	%fd151, [%rd1];
	st.local.f64 	[%rd4], %fd151;
	mov.u64 	%rd37, $str$3;
	cvta.global.u64 	%rd38, %rd37;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r59, [retval0+0];
	} // callseq 2
	ld.global.f64 	%fd152, [%rd1+24];
	st.local.f64 	[%rd4], %fd152;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r60, [retval0+0];
	} // callseq 3
	ld.global.f64 	%fd153, [%rd1+48];
	st.local.f64 	[%rd4], %fd153;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r61, [retval0+0];
	} // callseq 4
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r62, [retval0+0];
	} // callseq 5
	ld.global.f64 	%fd154, [%rd1+8];
	st.local.f64 	[%rd4], %fd154;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r63, [retval0+0];
	} // callseq 6
	ld.global.f64 	%fd155, [%rd1+32];
	st.local.f64 	[%rd4], %fd155;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r64, [retval0+0];
	} // callseq 7
	ld.global.f64 	%fd156, [%rd1+56];
	st.local.f64 	[%rd4], %fd156;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r65, [retval0+0];
	} // callseq 8
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r66, [retval0+0];
	} // callseq 9
	ld.global.f64 	%fd157, [%rd1+16];
	st.local.f64 	[%rd4], %fd157;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r67, [retval0+0];
	} // callseq 10
	ld.global.f64 	%fd158, [%rd1+40];
	st.local.f64 	[%rd4], %fd158;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r68, [retval0+0];
	} // callseq 11
	ld.global.f64 	%fd159, [%rd1+64];
	st.local.f64 	[%rd4], %fd159;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd20;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r69, [retval0+0];
	} // callseq 12
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r70, [retval0+0];
	} // callseq 13
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r71, [retval0+0];
	} // callseq 14

$L__BB0_22:
	ld.global.f64 	%fd12, [%rd1];
	abs.f64 	%fd160, %fd12;
	setp.gt.f64 	%p25, %fd160, %fd15;
	@%p25 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_23;

$L__BB0_32:
	ld.global.f64 	%fd167, [%rd1+32];
	abs.f64 	%fd168, %fd167;
	setp.gt.f64 	%p36, %fd168, %fd15;
	@%p36 bra 	$L__BB0_40;
	bra.uni 	$L__BB0_33;

$L__BB0_40:
	mov.u64 	%rd56, 4607182418800017408;
	st.global.u64 	[%rd3+16], %rd56;
	ld.global.f64 	%fd183, [%rd1+56];
	neg.f64 	%fd184, %fd183;
	ld.global.f64 	%fd185, [%rd1+32];
	div.rn.f64 	%fd186, %fd184, %fd185;
	st.global.f64 	[%rd3+8], %fd186;
	ld.global.f64 	%fd187, [%rd1+24];
	mul.f64 	%fd188, %fd186, %fd187;
	ld.global.f64 	%fd189, [%rd1+48];
	sub.f64 	%fd190, %fd188, %fd189;
	neg.f64 	%fd191, %fd190;
	ld.global.f64 	%fd192, [%rd1];
	div.rn.f64 	%fd193, %fd191, %fd192;
	st.global.f64 	[%rd3], %fd193;
	bra.uni 	$L__BB0_41;

$L__BB0_23:
	ld.global.f64 	%fd13, [%rd1+24];
	abs.f64 	%fd161, %fd13;
	setp.gt.f64 	%p26, %fd161, %fd15;
	@%p26 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_24;

$L__BB0_27:
	ld.global.f64 	%fd162, [%rd1+56];
	abs.f64 	%fd163, %fd162;
	setp.gt.f64 	%p31, %fd163, %fd15;
	@%p31 bra 	$L__BB0_31;
	bra.uni 	$L__BB0_28;

$L__BB0_31:
	mov.u64 	%rd47, 4607182418800017408;
	st.global.u64 	[%rd3], %rd47;
	mov.u64 	%rd48, 0;
	st.global.u64 	[%rd3+8], %rd48;
	st.global.u64 	[%rd3+16], %rd48;
	bra.uni 	$L__BB0_41;

$L__BB0_33:
	ld.global.f64 	%fd169, [%rd1+56];
	abs.f64 	%fd170, %fd169;
	setp.gt.f64 	%p37, %fd170, %fd15;
	@%p37 bra 	$L__BB0_39;
	bra.uni 	$L__BB0_34;

$L__BB0_39:
	ld.global.f64 	%fd180, [%rd1+24];
	neg.f64 	%fd181, %fd180;
	div.rn.f64 	%fd182, %fd181, %fd12;
	st.global.f64 	[%rd3], %fd182;
	mov.u64 	%rd54, 4607182418800017408;
	st.global.u64 	[%rd3+8], %rd54;
	mov.u64 	%rd55, 0;
	st.global.u64 	[%rd3+16], %rd55;
	bra.uni 	$L__BB0_41;

$L__BB0_24:
	and.b32  	%r72, %r1, 1;
	setp.eq.b32 	%p27, %r72, 1;
	mov.pred 	%p28, 0;
	xor.pred  	%p29, %p27, %p28;
	not.pred 	%p30, %p29;
	@%p30 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_25;

$L__BB0_26:
	mov.u64 	%rd41, 4607182418800017408;
	st.global.u64 	[%rd3], %rd41;
	mov.u64 	%rd42, 0;
	st.global.u64 	[%rd3+8], %rd42;
	st.global.u64 	[%rd3+16], %rd42;
	bra.uni 	$L__BB0_41;

$L__BB0_28:
	and.b32  	%r73, %r1, 1;
	setp.eq.b32 	%p32, %r73, 1;
	mov.pred 	%p33, 0;
	xor.pred  	%p34, %p32, %p33;
	not.pred 	%p35, %p34;
	@%p35 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_29;

$L__BB0_30:
	mov.u64 	%rd45, 4607182418800017408;
	st.global.u64 	[%rd3], %rd45;
	mov.u64 	%rd46, 0;
	st.global.u64 	[%rd3+8], %rd46;
	st.global.u64 	[%rd3+16], %rd46;
	bra.uni 	$L__BB0_41;

$L__BB0_34:
	mul.hi.s32 	%r74, %r1, 1431655766;
	shr.u32 	%r75, %r74, 31;
	add.s32 	%r76, %r74, %r75;
	mul.lo.s32 	%r77, %r76, 3;
	sub.s32 	%r78, %r1, %r77;
	setp.eq.s32 	%p38, %r78, 0;
	@%p38 bra 	$L__BB0_38;

	and.b32  	%r79, %r1, 1;
	setp.eq.b32 	%p39, %r79, 1;
	mov.pred 	%p40, 0;
	xor.pred  	%p41, %p39, %p40;
	not.pred 	%p42, %p41;
	ld.global.f64 	%fd14, [%rd1+24];
	@%p42 bra 	$L__BB0_37;
	bra.uni 	$L__BB0_36;

$L__BB0_37:
	neg.f64 	%fd175, %fd14;
	div.rn.f64 	%fd176, %fd175, %fd12;
	st.global.f64 	[%rd3], %fd176;
	mov.u64 	%rd50, 4607182418800017408;
	st.global.u64 	[%rd3+8], %rd50;
	mov.u64 	%rd51, 0;
	st.global.u64 	[%rd3+16], %rd51;
	bra.uni 	$L__BB0_41;

$L__BB0_25:
	mov.u64 	%rd39, 0;
	st.global.u64 	[%rd3], %rd39;
	mov.u64 	%rd40, 4607182418800017408;
	st.global.u64 	[%rd3+8], %rd40;
	st.global.u64 	[%rd3+16], %rd39;
	bra.uni 	$L__BB0_41;

$L__BB0_29:
	ld.global.f64 	%fd164, [%rd1+48];
	neg.f64 	%fd165, %fd164;
	div.rn.f64 	%fd166, %fd165, %fd13;
	mov.u64 	%rd43, 0;
	st.global.u64 	[%rd3], %rd43;
	st.global.f64 	[%rd3+8], %fd166;
	mov.u64 	%rd44, 4607182418800017408;
	st.global.u64 	[%rd3+16], %rd44;
	bra.uni 	$L__BB0_41;

$L__BB0_38:
	ld.global.f64 	%fd177, [%rd1+48];
	neg.f64 	%fd178, %fd177;
	div.rn.f64 	%fd179, %fd178, %fd12;
	st.global.f64 	[%rd3], %fd179;
	mov.u64 	%rd52, 0;
	st.global.u64 	[%rd3+8], %rd52;
	mov.u64 	%rd53, 4607182418800017408;
	st.global.u64 	[%rd3+16], %rd53;
	bra.uni 	$L__BB0_41;

$L__BB0_36:
	ld.global.f64 	%fd171, [%rd1+48];
	add.f64 	%fd172, %fd14, %fd171;
	neg.f64 	%fd173, %fd172;
	div.rn.f64 	%fd174, %fd173, %fd12;
	st.global.f64 	[%rd3], %fd174;
	mov.u64 	%rd49, 4607182418800017408;
	st.global.u64 	[%rd3+8], %rd49;
	st.global.u64 	[%rd3+16], %rd49;

$L__BB0_41:
	ret;

}

